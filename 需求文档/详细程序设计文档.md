# 股票自动交易系统详细程序设计文档

## 1. 核心架构设计

### 1.1 系统分层架构
```
┌─────────────────────────────────────────────────────────────┐
│                    应用服务层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ 策略执行器   │ │ 信号生成器   │ │ 风控检查器   │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    业务逻辑层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ 历史评分引擎 │ │ 股票池策略   │ │ 主力资金计算 │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    数据处理层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ Level2数据   │ │ 数据验证器   │ │ 缓存管理器   │           │
│  │ 接收器       │ │             │ │             │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    数据存储层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ PostgreSQL  │ │ Redis       │ │ InfluxDB    │           │
│  │ (主数据)     │ │ (缓存)       │ │ (时序数据)   │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 核心组件设计原则
- **单一职责**: 每个组件只负责一个特定功能
- **松耦合**: 组件间通过接口通信，降低依赖
- **高内聚**: 相关功能集中在同一组件内
- **可扩展**: 支持新增策略和算法
- **可测试**: 每个组件都可独立测试

### 1.3 数据流设计
```
Level2 API → 数据接收器 → 数据验证器 → 数据解析器
    ↓
缓存管理器 → 数据库存储 → 历史评分引擎 → 股票池策略
    ↓
信号生成器 → 风控检查器 → 交易执行器 → 交易记录
```

## 2. 核心类设计与实现

### 2.1 Level2数据处理核心类

#### 2.1.1 MarketDataReceiver - 行情数据接收器
```python
import logging
import threading
import time
from typing import Dict, List, Callable
from datetime import datetime
import lev2mdapi

class MarketDataReceiver(lev2mdapi.CTORATstpLev2MdSpi):
    """Level2行情数据接收器

    负责接收Level2实时行情数据，处理连接管理和数据分发
    """

    def __init__(self, config: Dict, data_handler: 'DataHandler'):
        super().__init__()
        self.config = config
        self.data_handler = data_handler
        self.api = None
        self.connected = False
        self.login_success = False
        self.subscriptions = set()

        # 日志配置
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

        # 连接状态监控
        self.connection_monitor = threading.Thread(target=self._monitor_connection, daemon=True)
        self.running = False

        # 性能统计
        self.stats = {
            'total_messages': 0,
            'market_data_count': 0,
            'transaction_count': 0,
            'order_detail_count': 0,
            'last_message_time': None,
            'connection_time': None
        }

    def initialize(self) -> bool:
        """初始化API连接"""
        try:
            self.logger.info("开始初始化Level2 API连接")

            # 创建API实例
            if self.config.get('connection_type') == 'udp':
                self.api = lev2mdapi.CTORATstpLev2MdApi_CreateTstpLev2MdApi(
                    lev2mdapi.TORA_TSTP_MST_MCAST,
                    self.config.get('cache_mode', False)
                )
                self.api.RegisterMulticast(
                    self.config['multicast_address'],
                    self.config['interface_ip'],
                    ""
                )
                self.logger.info(f"UDP组播模式初始化: {self.config['multicast_address']}")
            else:
                self.api = lev2mdapi.CTORATstpLev2MdApi_CreateTstpLev2MdApi(
                    lev2mdapi.TORA_TSTP_MST_TCP,
                    self.config.get('cache_mode', False)
                )
                self.api.RegisterFront(self.config['tcp_address'])
                self.logger.info(f"TCP模式初始化: {self.config['tcp_address']}")

            # 注册回调
            self.api.RegisterSpi(self)

            # 启动连接
            self.running = True
            self.api.Init()

            # 启动连接监控
            self.connection_monitor.start()

            self.logger.info("Level2 API初始化完成")
            return True

        except Exception as e:
            self.logger.error(f"Level2 API初始化失败: {e}", exc_info=True)
            return False

    def OnFrontConnected(self):
        """前置连接成功回调"""
        self.connected = True
        self.stats['connection_time'] = datetime.now()
        self.logger.info("Level2前置连接成功")

        # 发送登录请求
        self._send_login_request()

    def OnFrontDisconnected(self, nReason):
        """前置连接断开回调"""
        self.connected = False
        self.login_success = False
        self.logger.warning(f"Level2前置连接断开, 原因代码: {nReason}")

        # 触发重连机制
        self._handle_disconnection(nReason)

    def _send_login_request(self):
        """发送登录请求"""
        try:
            login_req = lev2mdapi.CTORATstpReqUserLoginField()

            if self.config.get('connection_type') != 'udp':
                # TCP模式需要填写认证信息
                login_req.LogInAccount = self.config['login_account']
                login_req.Password = self.config['password']
                login_req.LogInAccountType = lev2mdapi.TORA_TSTP_LACT_UnifiedUserID

                self.logger.info(f"发送TCP登录请求: {self.config['login_account']}")
            else:
                self.logger.info("发送UDP登录请求")

            result = self.api.ReqUserLogin(login_req, 1)
            if result != 0:
                self.logger.error(f"登录请求发送失败: {result}")

        except Exception as e:
            self.logger.error(f"发送登录请求异常: {e}", exc_info=True)

    def OnRspUserLogin(self, pRspUserLoginField, pRspInfo, nRequestID, bIsLast):
        """用户登录响应回调"""
        if pRspInfo['ErrorID'] == 0:
            self.login_success = True
            self.logger.info(f"Level2登录成功, RequestID: {nRequestID}")

            # 登录成功后开始订阅行情
            self._subscribe_market_data()

        else:
            self.login_success = False
            self.logger.error(f"Level2登录失败: [{pRspInfo['ErrorID']}] {pRspInfo['ErrorMsg']}")

    def _subscribe_market_data(self):
        """订阅行情数据"""
        try:
            # 获取订阅配置
            subscriptions = self.config.get('subscriptions', {})

            # 订阅快照行情
            if subscriptions.get('market_data', False):
                securities = subscriptions.get('securities', [b'00000000'])
                exchange = subscriptions.get('exchange', lev2mdapi.TORA_TSTP_EXD_COMM)

                result = self.api.SubscribeMarketData(securities, exchange)
                self.logger.info(f"订阅快照行情: {len(securities)}个证券, 结果: {result}")

            # 订阅逐笔成交
            if subscriptions.get('transaction', False):
                securities = subscriptions.get('transaction_securities', [b'00000000'])
                exchange = lev2mdapi.TORA_TSTP_EXD_SZSE  # 仅深圳支持

                result = self.api.SubscribeTransaction(securities, exchange)
                self.logger.info(f"订阅逐笔成交: {len(securities)}个证券, 结果: {result}")

            # 订阅逐笔委托
            if subscriptions.get('order_detail', False):
                securities = subscriptions.get('order_securities', [b'00000000'])
                exchange = lev2mdapi.TORA_TSTP_EXD_SZSE  # 仅深圳支持

                result = self.api.SubscribeOrderDetail(securities, exchange)
                self.logger.info(f"订阅逐笔委托: {len(securities)}个证券, 结果: {result}")

        except Exception as e:
            self.logger.error(f"订阅行情数据异常: {e}", exc_info=True)

    def OnRtnMarketData(self, pMarketData, FirstLevelBuyNum, FirstLevelBuyOrderVolumes,
                       FirstLevelSellNum, FirstLevelSellOrderVolumes):
        """快照行情数据推送回调"""
        try:
            self.stats['total_messages'] += 1
            self.stats['market_data_count'] += 1
            self.stats['last_message_time'] = datetime.now()

            # 数据标准化
            market_data = {
                'data_type': 'market_data',
                'stock_code': pMarketData['SecurityID'].decode('utf-8'),
                'exchange_id': pMarketData['ExchangeID'].decode('utf-8'),
                'timestamp': pMarketData['DataTimeStamp'],
                'last_price': pMarketData['LastPrice'],
                'pre_close_price': pMarketData['PreClosePrice'],
                'open_price': pMarketData['OpenPrice'],
                'high_price': pMarketData['HighestPrice'],
                'low_price': pMarketData['LowestPrice'],
                'volume': pMarketData['TotalVolumeTrade'],
                'amount': pMarketData['TotalValueTrade'],
                'bid_prices': [pMarketData[f'BidPrice{i}'] for i in range(1, 11)],
                'ask_prices': [pMarketData[f'AskPrice{i}'] for i in range(1, 11)],
                'bid_volumes': [pMarketData[f'BidVolume{i}'] for i in range(1, 11)],
                'ask_volumes': [pMarketData[f'AskVolume{i}'] for i in range(1, 11)],
                'receive_time': datetime.now()
            }

            # 记录详细日志
            self.logger.debug(
                f"接收快照行情: {market_data['stock_code']} "
                f"价格:{market_data['last_price']:.4f} "
                f"成交量:{market_data['volume']} "
                f"时间戳:{market_data['timestamp']}"
            )

            # 分发数据
            self.data_handler.handle_market_data(market_data)

        except Exception as e:
            self.logger.error(f"处理快照行情数据异常: {e}", exc_info=True)

    def OnRtnTransaction(self, pTransaction):
        """逐笔成交数据推送回调"""
        try:
            self.stats['total_messages'] += 1
            self.stats['transaction_count'] += 1
            self.stats['last_message_time'] = datetime.now()

            # 数据标准化
            transaction_data = {
                'data_type': 'transaction',
                'stock_code': pTransaction['SecurityID'].decode('utf-8'),
                'exchange_id': pTransaction['ExchangeID'].decode('utf-8'),
                'trade_time': pTransaction['TradeTime'],
                'trade_price': pTransaction['TradePrice'],
                'trade_volume': pTransaction['TradeVolume'],
                'exec_type': pTransaction['ExecType'].decode('utf-8'),
                'main_seq': pTransaction['MainSeq'],
                'sub_seq': pTransaction['SubSeq'],
                'buy_no': pTransaction['BuyNo'],
                'sell_no': pTransaction['SellNo'],
                'trade_bs_flag': pTransaction['TradeBSFlag'].decode('utf-8'),
                'receive_time': datetime.now()
            }

            # 记录详细日志
            self.logger.debug(
                f"接收逐笔成交: {transaction_data['stock_code']} "
                f"价格:{transaction_data['trade_price']:.4f} "
                f"数量:{transaction_data['trade_volume']} "
                f"方向:{transaction_data['trade_bs_flag']}"
            )

            # 分发数据
            self.data_handler.handle_transaction_data(transaction_data)

        except Exception as e:
            self.logger.error(f"处理逐笔成交数据异常: {e}", exc_info=True)

    def OnRtnOrderDetail(self, pOrderDetail):
        """逐笔委托数据推送回调"""
        try:
            self.stats['total_messages'] += 1
            self.stats['order_detail_count'] += 1
            self.stats['last_message_time'] = datetime.now()

            # 数据标准化
            order_data = {
                'data_type': 'order_detail',
                'stock_code': pOrderDetail['SecurityID'].decode('utf-8'),
                'exchange_id': pOrderDetail['ExchangeID'].decode('utf-8'),
                'order_time': pOrderDetail['OrderTime'],
                'price': pOrderDetail['Price'],
                'volume': pOrderDetail['Volume'],
                'order_type': pOrderDetail['OrderType'].decode('utf-8'),
                'main_seq': pOrderDetail['MainSeq'],
                'sub_seq': pOrderDetail['SubSeq'],
                'side': pOrderDetail['Side'].decode('utf-8'),
                'receive_time': datetime.now()
            }

            # 记录详细日志
            self.logger.debug(
                f"接收逐笔委托: {order_data['stock_code']} "
                f"价格:{order_data['price']:.4f} "
                f"数量:{order_data['volume']} "
                f"方向:{order_data['side']}"
            )

            # 分发数据
            self.data_handler.handle_order_detail_data(order_data)

        except Exception as e:
            self.logger.error(f"处理逐笔委托数据异常: {e}", exc_info=True)

    def _monitor_connection(self):
        """连接状态监控"""
        while self.running:
            try:
                # 检查连接状态
                if not self.connected:
                    self.logger.warning("检测到连接断开，尝试重连...")
                    # 这里可以添加重连逻辑

                # 检查数据接收状态
                if (self.stats['last_message_time'] and
                    (datetime.now() - self.stats['last_message_time']).seconds > 30):
                    self.logger.warning("超过30秒未收到数据，可能存在问题")

                # 记录统计信息
                if self.stats['total_messages'] > 0 and self.stats['total_messages'] % 10000 == 0:
                    self.logger.info(
                        f"数据接收统计: 总消息数:{self.stats['total_messages']} "
                        f"快照:{self.stats['market_data_count']} "
                        f"成交:{self.stats['transaction_count']} "
                        f"委托:{self.stats['order_detail_count']}"
                    )

                time.sleep(10)  # 每10秒检查一次

            except Exception as e:
                self.logger.error(f"连接监控异常: {e}", exc_info=True)

    def _handle_disconnection(self, reason_code: int):
        """处理连接断开"""
        self.logger.warning(f"处理连接断开事件, 原因代码: {reason_code}")

        # 根据断开原因采取不同策略
        if reason_code in [1, 2, 3]:  # 网络相关错误
            self.logger.info("网络连接问题，将在5秒后尝试重连")
            time.sleep(5)
            # 这里可以添加重连逻辑
        else:
            self.logger.error(f"未知断开原因: {reason_code}")

    def get_stats(self) -> Dict:
        """获取统计信息"""
        return self.stats.copy()

    def shutdown(self):
        """关闭连接"""
        self.logger.info("开始关闭Level2连接")
        self.running = False

        if self.api:
            self.api.Release()
            self.logger.info("Level2 API已释放")
```

#### 2.1.2 DataHandler - 数据处理器
```python
import logging
import asyncio
import threading
from typing import Dict, List, Callable, Any
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import json

class DataHandler:
    """数据处理器

    负责处理Level2数据的验证、转换、存储和分发
    """

    def __init__(self, db_manager: 'DatabaseManager',
                 cache_manager: 'CacheManager',
                 config: Dict):
        self.db_manager = db_manager
        self.cache_manager = cache_manager
        self.config = config

        # 日志配置
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

        # 数据订阅者
        self.subscribers = {}

        # 数据验证器
        self.validator = DataValidator(config)

        # 异步处理队列
        self.processing_queue = asyncio.Queue(maxsize=10000)
        self.batch_queue = []
        self.batch_size = config.get('batch_size', 100)
        self.batch_timeout = config.get('batch_timeout', 1.0)  # 秒

        # 线程池
        self.executor = ThreadPoolExecutor(max_workers=config.get('worker_threads', 4))

        # 统计信息
        self.stats = {
            'processed_count': 0,
            'error_count': 0,
            'last_process_time': None,
            'processing_latency': [],
            'batch_count': 0
        }

        # 启动异步处理
        self.running = True
        self.process_task = None
        self.batch_task = None

    async def start_processing(self):
        """启动异步数据处理"""
        self.logger.info("启动数据处理器")

        # 启动处理任务
        self.process_task = asyncio.create_task(self._process_data_loop())
        self.batch_task = asyncio.create_task(self._batch_process_loop())

        self.logger.info("数据处理器启动完成")

    def handle_market_data(self, market_data: Dict):
        """处理快照行情数据"""
        try:
            start_time = datetime.now()

            # 数据验证
            if not self.validator.validate_market_data(market_data):
                self.logger.warning(f"快照行情数据验证失败: {market_data['stock_code']}")
                self.stats['error_count'] += 1
                return

            # 添加处理时间戳
            market_data['process_time'] = start_time

            # 异步处理
            try:
                self.processing_queue.put_nowait({
                    'type': 'market_data',
                    'data': market_data,
                    'timestamp': start_time
                })
            except asyncio.QueueFull:
                self.logger.error("数据处理队列已满，丢弃数据")
                self.stats['error_count'] += 1

            # 记录处理延迟
            process_latency = (datetime.now() - start_time).total_seconds() * 1000
            self.stats['processing_latency'].append(process_latency)

            # 保持延迟统计数组大小
            if len(self.stats['processing_latency']) > 1000:
                self.stats['processing_latency'] = self.stats['processing_latency'][-1000:]

            self.logger.debug(
                f"快照行情入队: {market_data['stock_code']} "
                f"延迟:{process_latency:.2f}ms"
            )

        except Exception as e:
            self.logger.error(f"处理快照行情数据异常: {e}", exc_info=True)
            self.stats['error_count'] += 1

    def handle_transaction_data(self, transaction_data: Dict):
        """处理逐笔成交数据"""
        try:
            start_time = datetime.now()

            # 数据验证
            if not self.validator.validate_transaction_data(transaction_data):
                self.logger.warning(f"逐笔成交数据验证失败: {transaction_data['stock_code']}")
                self.stats['error_count'] += 1
                return

            # 添加处理时间戳
            transaction_data['process_time'] = start_time

            # 异步处理
            try:
                self.processing_queue.put_nowait({
                    'type': 'transaction',
                    'data': transaction_data,
                    'timestamp': start_time
                })
            except asyncio.QueueFull:
                self.logger.error("数据处理队列已满，丢弃逐笔成交数据")
                self.stats['error_count'] += 1

            self.logger.debug(
                f"逐笔成交入队: {transaction_data['stock_code']} "
                f"价格:{transaction_data['trade_price']:.4f}"
            )

        except Exception as e:
            self.logger.error(f"处理逐笔成交数据异常: {e}", exc_info=True)
            self.stats['error_count'] += 1

    def handle_order_detail_data(self, order_data: Dict):
        """处理逐笔委托数据"""
        try:
            start_time = datetime.now()

            # 数据验证
            if not self.validator.validate_order_data(order_data):
                self.logger.warning(f"逐笔委托数据验证失败: {order_data['stock_code']}")
                self.stats['error_count'] += 1
                return

            # 添加处理时间戳
            order_data['process_time'] = start_time

            # 异步处理
            try:
                self.processing_queue.put_nowait({
                    'type': 'order_detail',
                    'data': order_data,
                    'timestamp': start_time
                })
            except asyncio.QueueFull:
                self.logger.error("数据处理队列已满，丢弃逐笔委托数据")
                self.stats['error_count'] += 1

            self.logger.debug(
                f"逐笔委托入队: {order_data['stock_code']} "
                f"价格:{order_data['price']:.4f}"
            )

        except Exception as e:
            self.logger.error(f"处理逐笔委托数据异常: {e}", exc_info=True)
            self.stats['error_count'] += 1

    async def _process_data_loop(self):
        """数据处理主循环"""
        self.logger.info("启动数据处理主循环")

        while self.running:
            try:
                # 从队列获取数据
                item = await asyncio.wait_for(
                    self.processing_queue.get(),
                    timeout=1.0
                )

                # 处理数据
                await self._process_single_item(item)

                # 更新统计
                self.stats['processed_count'] += 1
                self.stats['last_process_time'] = datetime.now()

                # 标记任务完成
                self.processing_queue.task_done()

            except asyncio.TimeoutError:
                # 超时继续循环
                continue
            except Exception as e:
                self.logger.error(f"数据处理循环异常: {e}", exc_info=True)

    async def _process_single_item(self, item: Dict):
        """处理单个数据项"""
        try:
            data_type = item['type']
            data = item['data']

            # 根据数据类型分别处理
            if data_type == 'market_data':
                await self._process_market_data_item(data)
            elif data_type == 'transaction':
                await self._process_transaction_item(data)
            elif data_type == 'order_detail':
                await self._process_order_detail_item(data)

            # 通知订阅者
            await self._notify_subscribers(data_type, data)

        except Exception as e:
            self.logger.error(f"处理单个数据项异常: {e}", exc_info=True)

    async def _process_market_data_item(self, data: Dict):
        """处理快照行情数据项"""
        try:
            # 更新缓存
            await self.cache_manager.update_market_data(data)

            # 添加到批量处理队列
            self.batch_queue.append({
                'type': 'market_data',
                'data': data
            })

            self.logger.debug(f"处理快照行情: {data['stock_code']}")

        except Exception as e:
            self.logger.error(f"处理快照行情数据项异常: {e}", exc_info=True)

    async def _process_transaction_item(self, data: Dict):
        """处理逐笔成交数据项"""
        try:
            # 更新缓存
            await self.cache_manager.update_transaction_data(data)

            # 添加到批量处理队列
            self.batch_queue.append({
                'type': 'transaction',
                'data': data
            })

            self.logger.debug(f"处理逐笔成交: {data['stock_code']}")

        except Exception as e:
            self.logger.error(f"处理逐笔成交数据项异常: {e}", exc_info=True)

    async def _process_order_detail_item(self, data: Dict):
        """处理逐笔委托数据项"""
        try:
            # 更新缓存
            await self.cache_manager.update_order_detail_data(data)

            # 添加到批量处理队列
            self.batch_queue.append({
                'type': 'order_detail',
                'data': data
            })

            self.logger.debug(f"处理逐笔委托: {data['stock_code']}")

        except Exception as e:
            self.logger.error(f"处理逐笔委托数据项异常: {e}", exc_info=True)

    async def _batch_process_loop(self):
        """批量处理循环"""
        self.logger.info("启动批量处理循环")

        while self.running:
            try:
                await asyncio.sleep(self.batch_timeout)

                if len(self.batch_queue) >= self.batch_size or \
                   (len(self.batch_queue) > 0 and
                    (datetime.now() - self.stats.get('last_batch_time', datetime.now())).seconds >= self.batch_timeout):

                    # 执行批量处理
                    await self._execute_batch_process()

            except Exception as e:
                self.logger.error(f"批量处理循环异常: {e}", exc_info=True)

    async def _execute_batch_process(self):
        """执行批量处理"""
        if not self.batch_queue:
            return

        try:
            batch_data = self.batch_queue.copy()
            self.batch_queue.clear()

            self.logger.info(f"执行批量处理: {len(batch_data)}条数据")

            # 分类数据
            market_data_batch = []
            transaction_batch = []
            order_detail_batch = []

            for item in batch_data:
                if item['type'] == 'market_data':
                    market_data_batch.append(item['data'])
                elif item['type'] == 'transaction':
                    transaction_batch.append(item['data'])
                elif item['type'] == 'order_detail':
                    order_detail_batch.append(item['data'])

            # 并行批量存储
            tasks = []
            if market_data_batch:
                tasks.append(self.db_manager.batch_insert_market_data(market_data_batch))
            if transaction_batch:
                tasks.append(self.db_manager.batch_insert_transactions(transaction_batch))
            if order_detail_batch:
                tasks.append(self.db_manager.batch_insert_order_details(order_detail_batch))

            if tasks:
                await asyncio.gather(*tasks)

            # 更新统计
            self.stats['batch_count'] += 1
            self.stats['last_batch_time'] = datetime.now()

            self.logger.info(
                f"批量处理完成: 快照{len(market_data_batch)} "
                f"成交{len(transaction_batch)} 委托{len(order_detail_batch)}"
            )

        except Exception as e:
            self.logger.error(f"执行批量处理异常: {e}", exc_info=True)

    def subscribe(self, data_type: str, callback: Callable):
        """订阅数据更新"""
        if data_type not in self.subscribers:
            self.subscribers[data_type] = []

        self.subscribers[data_type].append(callback)
        self.logger.info(f"添加数据订阅: {data_type}")

    async def _notify_subscribers(self, data_type: str, data: Dict):
        """通知订阅者"""
        if data_type in self.subscribers:
            for callback in self.subscribers[data_type]:
                try:
                    if asyncio.iscoroutinefunction(callback):
                        await callback(data)
                    else:
                        callback(data)
                except Exception as e:
                    self.logger.error(f"通知订阅者异常: {e}", exc_info=True)

    def get_stats(self) -> Dict:
        """获取统计信息"""
        stats = self.stats.copy()

        # 计算平均延迟
        if self.stats['processing_latency']:
            stats['avg_latency'] = sum(self.stats['processing_latency']) / len(self.stats['processing_latency'])
            stats['max_latency'] = max(self.stats['processing_latency'])
            stats['min_latency'] = min(self.stats['processing_latency'])

        # 队列状态
        stats['queue_size'] = self.processing_queue.qsize()
        stats['batch_queue_size'] = len(self.batch_queue)

        return stats

    async def shutdown(self):
        """关闭数据处理器"""
        self.logger.info("开始关闭数据处理器")

        self.running = False

        # 等待队列处理完成
        await self.processing_queue.join()

        # 处理剩余批量数据
        if self.batch_queue:
            await self._execute_batch_process()

        # 取消任务
        if self.process_task:
            self.process_task.cancel()
        if self.batch_task:
            self.batch_task.cancel()

        # 关闭线程池
        self.executor.shutdown(wait=True)

        self.logger.info("数据处理器已关闭")
```

### 2.2 历史评分引擎核心类

#### 2.2.1 HistoricalScoreEngine - 历史评分引擎
```python
import logging
import asyncio
from typing import Dict, List, Optional, Tuple
from datetime import datetime, date
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd
from abc import ABC, abstractmethod

class HistoricalScoreEngine:
    """历史评分引擎

    负责计算股票的历史评分，支持6种评分算法
    """

    def __init__(self, db_manager: 'DatabaseManager',
                 config_manager: 'ConfigManager'):
        self.db_manager = db_manager
        self.config_manager = config_manager

        # 日志配置
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

        # 初始化评分器
        self.scorers = self._initialize_scorers()

        # 线程池用于并行计算
        self.executor = ThreadPoolExecutor(
            max_workers=config_manager.get('score_engine.max_workers', 8)
        )

        # 统计信息
        self.stats = {
            'total_calculations': 0,
            'successful_calculations': 0,
            'failed_calculations': 0,
            'last_calculation_time': None,
            'calculation_times': []
        }

    def _initialize_scorers(self) -> Dict[str, 'BaseScorer']:
        """初始化各种评分器"""
        scorers = {
            'limit_up_break': LimitUpBreakScorer(self.config_manager),
            'decline_score': DeclineScorer(self.config_manager),
            'limit_up_seal': LimitUpSealScorer(self.config_manager),
            'limit_up_time': LimitUpTimeScorer(self.config_manager),
            'continuous_decline': ContinuousDeclineScorer(self.config_manager),
            'limit_up_reseal': LimitUpResealScorer(self.config_manager)
        }

        self.logger.info(f"初始化评分器完成: {list(scorers.keys())}")
        return scorers

    async def calculate_daily_scores(self, trade_date: str) -> Dict[str, Dict]:
        """计算指定日期的所有股票评分

        Args:
            trade_date: 交易日期 (YYYY-MM-DD)

        Returns:
            Dict: {stock_code: {scorer_name: score_value}}
        """
        start_time = datetime.now()
        self.logger.info(f"开始计算日期 {trade_date} 的历史评分")

        try:
            # 获取活跃股票列表
            stock_list = await self.db_manager.get_active_stocks()
            self.logger.info(f"获取到 {len(stock_list)} 只活跃股票")

            # 并行计算所有股票的评分
            results = {}
            batch_size = self.config_manager.get('score_engine.batch_size', 100)

            for i in range(0, len(stock_list), batch_size):
                batch = stock_list[i:i + batch_size]
                batch_results = await self._calculate_batch_scores(batch, trade_date)
                results.update(batch_results)

                self.logger.info(
                    f"完成批次 {i//batch_size + 1}/{(len(stock_list)-1)//batch_size + 1} "
                    f"({len(batch)} 只股票)"
                )

            # 保存评分结果
            await self._save_scores(results, trade_date)

            # 更新统计信息
            calculation_time = (datetime.now() - start_time).total_seconds()
            self.stats['total_calculations'] += len(stock_list)
            self.stats['successful_calculations'] += len(results)
            self.stats['last_calculation_time'] = datetime.now()
            self.stats['calculation_times'].append(calculation_time)

            self.logger.info(
                f"日期 {trade_date} 评分计算完成: "
                f"成功 {len(results)}/{len(stock_list)} 只股票, "
                f"耗时 {calculation_time:.2f} 秒"
            )

            return results

        except Exception as e:
            self.logger.error(f"计算日期 {trade_date} 评分异常: {e}", exc_info=True)
            raise

    async def _calculate_batch_scores(self, stock_batch: List[str],
                                    trade_date: str) -> Dict[str, Dict]:
        """批量计算股票评分"""
        results = {}

        # 获取批量历史数据
        historical_data = await self.db_manager.get_batch_historical_data(
            stock_batch, trade_date
        )

        # 并行计算每只股票的评分
        tasks = []
        for stock_code in stock_batch:
            if stock_code in historical_data:
                task = asyncio.create_task(
                    self._calculate_single_stock_score(
                        stock_code, historical_data[stock_code], trade_date
                    )
                )
                tasks.append((stock_code, task))

        # 等待所有任务完成
        for stock_code, task in tasks:
            try:
                score_result = await task
                if score_result:
                    results[stock_code] = score_result
            except Exception as e:
                self.logger.error(f"计算股票 {stock_code} 评分异常: {e}")
                self.stats['failed_calculations'] += 1

        return results

    async def _calculate_single_stock_score(self, stock_code: str,
                                          stock_data: Dict,
                                          trade_date: str) -> Optional[Dict]:
        """计算单只股票的评分"""
        try:
            scores = {}
            calculation_details = {}

            # 并行执行所有评分器
            scorer_tasks = []
            for scorer_name, scorer in self.scorers.items():
                task = asyncio.create_task(
                    self._run_scorer(scorer, stock_code, stock_data, trade_date)
                )
                scorer_tasks.append((scorer_name, task))

            # 收集评分结果
            for scorer_name, task in scorer_tasks:
                try:
                    score_result = await task
                    if score_result is not None:
                        scores[scorer_name] = score_result['score']
                        calculation_details[scorer_name] = score_result['details']

                        self.logger.debug(
                            f"股票 {stock_code} {scorer_name} 评分: {score_result['score']:.4f}"
                        )
                except Exception as e:
                    self.logger.warning(
                        f"股票 {stock_code} 评分器 {scorer_name} 计算失败: {e}"
                    )
                    scores[scorer_name] = 0.0
                    calculation_details[scorer_name] = {'error': str(e)}

            # 计算综合评分
            total_score = sum(scores.values())

            result = {
                'individual_scores': scores,
                'total_score': total_score,
                'calculation_details': calculation_details,
                'calculation_time': datetime.now()
            }

            self.logger.debug(
                f"股票 {stock_code} 评分完成: 总分 {total_score:.4f}, "
                f"明细 {scores}"
            )

            return result

        except Exception as e:
            self.logger.error(f"计算股票 {stock_code} 评分异常: {e}", exc_info=True)
            return None

    async def _run_scorer(self, scorer: 'BaseScorer', stock_code: str,
                         stock_data: Dict, trade_date: str) -> Optional[Dict]:
        """运行单个评分器"""
        try:
            # 检查数据完整性
            required_data = scorer.get_required_data()
            for field in required_data:
                if field not in stock_data or stock_data[field] is None:
                    self.logger.warning(
                        f"股票 {stock_code} 缺少必需数据字段: {field}"
                    )
                    return None

            # 执行评分计算
            score_result = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                scorer.calculate_score,
                stock_code,
                stock_data,
                trade_date
            )

            return score_result

        except Exception as e:
            self.logger.error(
                f"运行评分器 {scorer.__class__.__name__} 异常: {e}",
                exc_info=True
            )
            return None

    async def _save_scores(self, scores: Dict[str, Dict], trade_date: str):
        """保存评分结果到数据库"""
        try:
            self.logger.info(f"开始保存 {len(scores)} 只股票的评分结果")

            # 准备批量插入数据
            score_records = []
            for stock_code, stock_scores in scores.items():
                for scorer_name, score_value in stock_scores['individual_scores'].items():
                    record = {
                        'stock_code': stock_code,
                        'trade_date': trade_date,
                        'score_type': scorer_name,
                        'score_value': score_value,
                        'calculation_params': stock_scores['calculation_details'].get(scorer_name, {}),
                        'total_score': stock_scores['total_score'],
                        'created_at': datetime.now()
                    }
                    score_records.append(record)

            # 批量插入数据库
            await self.db_manager.batch_insert_historical_scores(score_records)

            self.logger.info(f"评分结果保存完成: {len(score_records)} 条记录")

        except Exception as e:
            self.logger.error(f"保存评分结果异常: {e}", exc_info=True)
            raise

    async def get_stock_scores(self, stock_code: str,
                             start_date: str, end_date: str) -> List[Dict]:
        """获取股票历史评分"""
        try:
            scores = await self.db_manager.get_historical_scores(
                stock_code, start_date, end_date
            )

            self.logger.debug(
                f"获取股票 {stock_code} 历史评分: "
                f"{start_date} 到 {end_date}, {len(scores)} 条记录"
            )

            return scores

        except Exception as e:
            self.logger.error(f"获取股票 {stock_code} 历史评分异常: {e}", exc_info=True)
            return []

    def get_stats(self) -> Dict:
        """获取统计信息"""
        stats = self.stats.copy()

        if self.stats['calculation_times']:
            stats['avg_calculation_time'] = sum(self.stats['calculation_times']) / len(self.stats['calculation_times'])
            stats['max_calculation_time'] = max(self.stats['calculation_times'])
            stats['min_calculation_time'] = min(self.stats['calculation_times'])

        return stats

    def shutdown(self):
        """关闭评分引擎"""
        self.logger.info("关闭历史评分引擎")
        self.executor.shutdown(wait=True)
        self.logger.info("历史评分引擎已关闭")


class BaseScorer(ABC):
    """评分器基类"""

    def __init__(self, config_manager: 'ConfigManager'):
        self.config_manager = config_manager
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

    @abstractmethod
    def calculate_score(self, stock_code: str, stock_data: Dict,
                       trade_date: str) -> Dict:
        """计算评分

        Returns:
            Dict: {
                'score': float,
                'details': Dict  # 计算详情
            }
        """
        pass

    @abstractmethod
    def get_required_data(self) -> List[str]:
        """获取所需数据字段"""
        pass

    def _get_config_value(self, key: str, default_value: float) -> float:
        """获取配置值"""
        return self.config_manager.get(f"scorers.{self.__class__.__name__.lower()}.{key}", default_value)


class LimitUpBreakScorer(BaseScorer):
    """涨停炸板评分器"""

    def calculate_score(self, stock_code: str, stock_data: Dict,
                       trade_date: str) -> Dict:
        """计算涨停炸板评分

        算法: |（最高价-收盘价）/前一日收盘价| * X1%
        """
        try:
            # 获取配置参数
            x1_percent = self._get_config_value('x1_percent', 1.0)

            # 获取数据
            high_price = stock_data['high_price']
            close_price = stock_data['close_price']
            prev_close_price = stock_data['prev_close_price']
            limit_up_price = stock_data.get('limit_up_price')

            # 检查是否涨停炸板
            is_limit_up = abs(high_price - limit_up_price) < 0.01 if limit_up_price else False
            is_break = close_price < high_price

            if is_limit_up and is_break:
                # 计算炸板幅度
                break_ratio = abs((high_price - close_price) / prev_close_price)
                score = break_ratio * x1_percent

                details = {
                    'is_limit_up': True,
                    'is_break': True,
                    'high_price': high_price,
                    'close_price': close_price,
                    'prev_close_price': prev_close_price,
                    'break_ratio': break_ratio,
                    'x1_percent': x1_percent
                }

                self.logger.debug(
                    f"股票 {stock_code} 涨停炸板评分: {score:.4f} "
                    f"(炸板幅度: {break_ratio:.4f})"
                )
            else:
                score = 0.0
                details = {
                    'is_limit_up': is_limit_up,
                    'is_break': is_break,
                    'reason': '未满足涨停炸板条件'
                }

            return {
                'score': score,
                'details': details
            }

        except Exception as e:
            self.logger.error(f"计算涨停炸板评分异常: {e}", exc_info=True)
            return {
                'score': 0.0,
                'details': {'error': str(e)}
            }

    def get_required_data(self) -> List[str]:
        """获取所需数据字段"""
        return [
            'high_price', 'close_price', 'prev_close_price',
            'limit_up_price'
        ]


class DeclineScorer(BaseScorer):
    """跌幅评分器"""

    def calculate_score(self, stock_code: str, stock_data: Dict,
                       trade_date: str) -> Dict:
        """计算跌幅评分

        算法: 收盘涨幅<-2% 时，|（最高价-收盘价）/前一日收盘价| * X2%
        """
        try:
            # 获取配置参数
            x2_percent = self._get_config_value('x2_percent', 1.0)
            decline_threshold = self._get_config_value('decline_threshold', -0.02)

            # 获取数据
            high_price = stock_data['high_price']
            close_price = stock_data['close_price']
            prev_close_price = stock_data['prev_close_price']

            # 计算涨跌幅
            price_change_ratio = (close_price - prev_close_price) / prev_close_price

            if price_change_ratio < decline_threshold:
                # 计算最高价与收盘价差异
                price_diff_ratio = abs((high_price - close_price) / prev_close_price)
                score = price_diff_ratio * x2_percent

                details = {
                    'meets_condition': True,
                    'price_change_ratio': price_change_ratio,
                    'price_diff_ratio': price_diff_ratio,
                    'x2_percent': x2_percent,
                    'decline_threshold': decline_threshold
                }

                self.logger.debug(
                    f"股票 {stock_code} 跌幅评分: {score:.4f} "
                    f"(跌幅: {price_change_ratio:.4f})"
                )
            else:
                score = 0.0
                details = {
                    'meets_condition': False,
                    'price_change_ratio': price_change_ratio,
                    'decline_threshold': decline_threshold,
                    'reason': '跌幅未达到阈值'
                }

            return {
                'score': score,
                'details': details
            }

        except Exception as e:
            self.logger.error(f"计算跌幅评分异常: {e}", exc_info=True)
            return {
                'score': 0.0,
                'details': {'error': str(e)}
            }

    def get_required_data(self) -> List[str]:
        """获取所需数据字段"""
        return ['high_price', 'close_price', 'prev_close_price']
```

## 3. 详细日志系统设计

### 3.1 日志架构设计

#### 3.1.1 日志分层结构
```
┌─────────────────────────────────────────────────────────────┐
│                    应用日志层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ 业务日志     │ │ 性能日志     │ │ 错误日志     │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    系统日志层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ 数据流日志   │ │ 连接日志     │ │ 配置日志     │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    基础设施层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ 文件日志     │ │ 数据库日志   │ │ 监控日志     │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
└─────────────────────────────────────────────────────────────┘
```

#### 3.1.2 LogManager - 日志管理器
```python
import logging
import logging.handlers
import json
import os
import threading
from typing import Dict, Any, Optional
from datetime import datetime
from pathlib import Path
import gzip
import shutil

class LogManager:
    """统一日志管理器

    提供结构化日志记录、日志轮转、日志聚合等功能
    """

    def __init__(self, config: Dict):
        self.config = config
        self.loggers = {}
        self.handlers = {}
        self.formatters = {}

        # 创建日志目录
        self.log_dir = Path(config.get('log_dir', './logs'))
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # 初始化日志系统
        self._setup_formatters()
        self._setup_handlers()
        self._setup_loggers()

        # 日志统计
        self.stats = {
            'total_logs': 0,
            'error_logs': 0,
            'warning_logs': 0,
            'info_logs': 0,
            'debug_logs': 0,
            'last_log_time': None
        }

        # 启动日志监控
        self.monitor_thread = threading.Thread(target=self._monitor_logs, daemon=True)
        self.monitor_thread.start()

    def _setup_formatters(self):
        """设置日志格式器"""

        # JSON格式器 - 用于结构化日志
        class JsonFormatter(logging.Formatter):
            def format(self, record):
                log_entry = {
                    'timestamp': datetime.fromtimestamp(record.created).isoformat(),
                    'level': record.levelname,
                    'logger': record.name,
                    'module': record.module,
                    'function': record.funcName,
                    'line': record.lineno,
                    'message': record.getMessage(),
                    'thread_id': record.thread,
                    'thread_name': record.threadName,
                    'process_id': record.process
                }

                # 添加异常信息
                if record.exc_info:
                    log_entry['exception'] = self.formatException(record.exc_info)

                # 添加自定义字段
                if hasattr(record, 'extra_fields'):
                    log_entry.update(record.extra_fields)

                return json.dumps(log_entry, ensure_ascii=False)

        # 标准格式器 - 用于控制台输出
        standard_format = (
            '%(asctime)s - %(name)s - %(levelname)s - '
            '[%(filename)s:%(lineno)d] - %(message)s'
        )

        # 性能格式器 - 用于性能日志
        performance_format = (
            '%(asctime)s - PERF - %(name)s - '
            'Duration: %(duration).3fms - %(message)s'
        )

        self.formatters = {
            'json': JsonFormatter(),
            'standard': logging.Formatter(standard_format),
            'performance': logging.Formatter(performance_format)
        }

    def _setup_handlers(self):
        """设置日志处理器"""

        # 控制台处理器
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(self.formatters['standard'])
        self.handlers['console'] = console_handler

        # 应用日志文件处理器
        app_handler = logging.handlers.RotatingFileHandler(
            filename=self.log_dir / 'application.log',
            maxBytes=self.config.get('max_file_size', 100 * 1024 * 1024),  # 100MB
            backupCount=self.config.get('backup_count', 10),
            encoding='utf-8'
        )
        app_handler.setLevel(logging.INFO)
        app_handler.setFormatter(self.formatters['json'])
        self.handlers['application'] = app_handler

        # 错误日志文件处理器
        error_handler = logging.handlers.RotatingFileHandler(
            filename=self.log_dir / 'error.log',
            maxBytes=self.config.get('max_file_size', 50 * 1024 * 1024),  # 50MB
            backupCount=self.config.get('backup_count', 20),
            encoding='utf-8'
        )
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(self.formatters['json'])
        self.handlers['error'] = error_handler

        # 性能日志处理器
        perf_handler = logging.handlers.RotatingFileHandler(
            filename=self.log_dir / 'performance.log',
            maxBytes=self.config.get('max_file_size', 50 * 1024 * 1024),
            backupCount=self.config.get('backup_count', 10),
            encoding='utf-8'
        )
        perf_handler.setLevel(logging.INFO)
        perf_handler.setFormatter(self.formatters['performance'])
        self.handlers['performance'] = perf_handler

        # 数据流日志处理器
        data_handler = logging.handlers.RotatingFileHandler(
            filename=self.log_dir / 'dataflow.log',
            maxBytes=self.config.get('max_file_size', 200 * 1024 * 1024),  # 200MB
            backupCount=self.config.get('backup_count', 5),
            encoding='utf-8'
        )
        data_handler.setLevel(logging.DEBUG)
        data_handler.setFormatter(self.formatters['json'])
        self.handlers['dataflow'] = data_handler

        # 交易日志处理器
        trade_handler = logging.handlers.RotatingFileHandler(
            filename=self.log_dir / 'trading.log',
            maxBytes=self.config.get('max_file_size', 100 * 1024 * 1024),
            backupCount=self.config.get('backup_count', 20),
            encoding='utf-8'
        )
        trade_handler.setLevel(logging.INFO)
        trade_handler.setFormatter(self.formatters['json'])
        self.handlers['trading'] = trade_handler

        # 策略日志处理器
        strategy_handler = logging.handlers.RotatingFileHandler(
            filename=self.log_dir / 'strategy.log',
            maxBytes=self.config.get('max_file_size', 100 * 1024 * 1024),
            backupCount=self.config.get('backup_count', 10),
            encoding='utf-8'
        )
        strategy_handler.setLevel(logging.INFO)
        strategy_handler.setFormatter(self.formatters['json'])
        self.handlers['strategy'] = strategy_handler

    def _setup_loggers(self):
        """设置日志记录器"""

        # 根日志记录器
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.DEBUG)

        # 应用日志记录器
        app_logger = logging.getLogger('trading_system')
        app_logger.setLevel(logging.DEBUG)
        app_logger.addHandler(self.handlers['console'])
        app_logger.addHandler(self.handlers['application'])
        app_logger.addHandler(self.handlers['error'])
        app_logger.propagate = False
        self.loggers['application'] = app_logger

        # 性能日志记录器
        perf_logger = logging.getLogger('trading_system.performance')
        perf_logger.setLevel(logging.INFO)
        perf_logger.addHandler(self.handlers['performance'])
        perf_logger.propagate = False
        self.loggers['performance'] = perf_logger

        # 数据流日志记录器
        data_logger = logging.getLogger('trading_system.dataflow')
        data_logger.setLevel(logging.DEBUG)
        data_logger.addHandler(self.handlers['dataflow'])
        data_logger.propagate = False
        self.loggers['dataflow'] = data_logger

        # 交易日志记录器
        trade_logger = logging.getLogger('trading_system.trading')
        trade_logger.setLevel(logging.INFO)
        trade_logger.addHandler(self.handlers['trading'])
        trade_logger.propagate = False
        self.loggers['trading'] = trade_logger

        # 策略日志记录器
        strategy_logger = logging.getLogger('trading_system.strategy')
        strategy_logger.setLevel(logging.INFO)
        strategy_logger.addHandler(self.handlers['strategy'])
        strategy_logger.propagate = False
        self.loggers['strategy'] = strategy_logger

    def get_logger(self, name: str) -> logging.Logger:
        """获取指定名称的日志记录器"""
        return logging.getLogger(f'trading_system.{name}')

    def log_performance(self, operation: str, duration: float,
                       details: Optional[Dict] = None):
        """记录性能日志"""
        perf_logger = self.loggers['performance']

        extra = {
            'duration': duration,
            'extra_fields': {
                'operation': operation,
                'duration_ms': duration,
                'details': details or {}
            }
        }

        perf_logger.info(f"Operation: {operation}", extra=extra)
        self._update_stats('info')

    def log_data_flow(self, data_type: str, stock_code: str,
                     action: str, details: Dict):
        """记录数据流日志"""
        data_logger = self.loggers['dataflow']

        extra = {
            'extra_fields': {
                'data_type': data_type,
                'stock_code': stock_code,
                'action': action,
                'details': details
            }
        }

        data_logger.debug(
            f"DataFlow: {action} {data_type} for {stock_code}",
            extra=extra
        )
        self._update_stats('debug')

    def log_trading_action(self, action: str, stock_code: str,
                          details: Dict, level: str = 'info'):
        """记录交易行为日志"""
        trade_logger = self.loggers['trading']

        extra = {
            'extra_fields': {
                'action': action,
                'stock_code': stock_code,
                'details': details,
                'timestamp': datetime.now().isoformat()
            }
        }

        message = f"Trading: {action} for {stock_code}"

        if level == 'error':
            trade_logger.error(message, extra=extra)
        elif level == 'warning':
            trade_logger.warning(message, extra=extra)
        else:
            trade_logger.info(message, extra=extra)

        self._update_stats(level)

    def log_strategy_execution(self, strategy_name: str, action: str,
                             results: Dict, level: str = 'info'):
        """记录策略执行日志"""
        strategy_logger = self.loggers['strategy']

        extra = {
            'extra_fields': {
                'strategy_name': strategy_name,
                'action': action,
                'results': results,
                'timestamp': datetime.now().isoformat()
            }
        }

        message = f"Strategy: {strategy_name} - {action}"

        if level == 'error':
            strategy_logger.error(message, extra=extra)
        elif level == 'warning':
            strategy_logger.warning(message, extra=extra)
        else:
            strategy_logger.info(message, extra=extra)

        self._update_stats(level)

    def _update_stats(self, level: str):
        """更新日志统计"""
        self.stats['total_logs'] += 1
        self.stats[f'{level}_logs'] += 1
        self.stats['last_log_time'] = datetime.now()

    def _monitor_logs(self):
        """监控日志状态"""
        import time

        while True:
            try:
                # 检查日志文件大小
                for handler_name, handler in self.handlers.items():
                    if hasattr(handler, 'baseFilename'):
                        file_path = Path(handler.baseFilename)
                        if file_path.exists():
                            file_size = file_path.stat().st_size
                            if file_size > handler.maxBytes * 0.9:  # 90%阈值
                                app_logger = self.loggers['application']
                                app_logger.warning(
                                    f"日志文件 {handler_name} 接近大小限制: "
                                    f"{file_size / 1024 / 1024:.1f}MB"
                                )

                # 清理旧日志文件
                self._cleanup_old_logs()

                time.sleep(300)  # 每5分钟检查一次

            except Exception as e:
                print(f"日志监控异常: {e}")
                time.sleep(60)

    def _cleanup_old_logs(self):
        """清理旧日志文件"""
        try:
            retention_days = self.config.get('log_retention_days', 30)
            cutoff_time = datetime.now().timestamp() - (retention_days * 24 * 3600)

            for log_file in self.log_dir.glob('*.log.*'):
                if log_file.stat().st_mtime < cutoff_time:
                    # 压缩旧日志文件
                    if not log_file.name.endswith('.gz'):
                        with open(log_file, 'rb') as f_in:
                            with gzip.open(f"{log_file}.gz", 'wb') as f_out:
                                shutil.copyfileobj(f_in, f_out)
                        log_file.unlink()

                    # 删除过期的压缩文件
                    elif log_file.stat().st_mtime < cutoff_time - (7 * 24 * 3600):
                        log_file.unlink()

        except Exception as e:
            app_logger = self.loggers.get('application')
            if app_logger:
                app_logger.error(f"清理旧日志文件异常: {e}")

    def get_stats(self) -> Dict:
        """获取日志统计信息"""
        return self.stats.copy()

    def shutdown(self):
        """关闭日志系统"""
        for handler in self.handlers.values():
            handler.close()
```

### 3.2 专用日志记录器

#### 3.2.1 PerformanceLogger - 性能日志记录器
```python
import time
from contextlib import contextmanager
from typing import Dict, Any, Optional
from datetime import datetime

class PerformanceLogger:
    """性能日志记录器

    专门用于记录系统性能指标和执行时间
    """

    def __init__(self, log_manager: LogManager):
        self.log_manager = log_manager
        self.logger = log_manager.get_logger('performance')

        # 性能指标缓存
        self.metrics_cache = {}
        self.operation_times = {}

    @contextmanager
    def measure_time(self, operation: str, details: Optional[Dict] = None):
        """测量操作执行时间的上下文管理器"""
        start_time = time.perf_counter()
        start_timestamp = datetime.now()

        try:
            yield
        finally:
            end_time = time.perf_counter()
            duration = (end_time - start_time) * 1000  # 转换为毫秒

            # 记录性能日志
            self.log_operation_time(operation, duration, details)

            # 更新操作时间统计
            if operation not in self.operation_times:
                self.operation_times[operation] = []
            self.operation_times[operation].append(duration)

            # 保持统计数组大小
            if len(self.operation_times[operation]) > 1000:
                self.operation_times[operation] = self.operation_times[operation][-1000:]

    def log_operation_time(self, operation: str, duration: float,
                          details: Optional[Dict] = None):
        """记录操作执行时间"""
        self.log_manager.log_performance(operation, duration, details)

        # 检查性能阈值
        threshold = self._get_performance_threshold(operation)
        if duration > threshold:
            self.logger.warning(
                f"性能告警: {operation} 执行时间 {duration:.2f}ms 超过阈值 {threshold}ms",
                extra={
                    'extra_fields': {
                        'operation': operation,
                        'duration': duration,
                        'threshold': threshold,
                        'details': details or {}
                    }
                }
            )

    def log_throughput(self, operation: str, count: int, duration: float):
        """记录吞吐量指标"""
        throughput = count / (duration / 1000) if duration > 0 else 0

        self.logger.info(
            f"吞吐量: {operation} - {throughput:.2f} ops/sec",
            extra={
                'extra_fields': {
                    'operation': operation,
                    'count': count,
                    'duration': duration,
                    'throughput': throughput
                }
            }
        )

    def log_resource_usage(self, cpu_percent: float, memory_mb: float,
                          disk_io: Dict, network_io: Dict):
        """记录资源使用情况"""
        self.logger.info(
            f"资源使用: CPU {cpu_percent:.1f}%, 内存 {memory_mb:.1f}MB",
            extra={
                'extra_fields': {
                    'cpu_percent': cpu_percent,
                    'memory_mb': memory_mb,
                    'disk_io': disk_io,
                    'network_io': network_io,
                    'timestamp': datetime.now().isoformat()
                }
            }
        )

    def _get_performance_threshold(self, operation: str) -> float:
        """获取操作的性能阈值"""
        thresholds = {
            'data_processing': 100.0,  # 100ms
            'database_query': 50.0,    # 50ms
            'cache_operation': 10.0,   # 10ms
            'strategy_calculation': 200.0,  # 200ms
            'score_calculation': 500.0,     # 500ms
        }
        return thresholds.get(operation, 1000.0)  # 默认1秒

    def get_operation_stats(self, operation: str) -> Dict:
        """获取操作统计信息"""
        if operation not in self.operation_times:
            return {}

        times = self.operation_times[operation]
        return {
            'count': len(times),
            'avg_time': sum(times) / len(times),
            'min_time': min(times),
            'max_time': max(times),
            'p95_time': sorted(times)[int(len(times) * 0.95)] if times else 0,
            'p99_time': sorted(times)[int(len(times) * 0.99)] if times else 0
        }
```

#### 3.2.2 TradingLogger - 交易日志记录器
```python
from enum import Enum
from typing import Dict, Any, Optional, List
from datetime import datetime
import json

class TradingAction(Enum):
    """交易行为枚举"""
    SIGNAL_GENERATED = "signal_generated"
    ORDER_CREATED = "order_created"
    ORDER_SUBMITTED = "order_submitted"
    ORDER_FILLED = "order_filled"
    ORDER_CANCELLED = "order_cancelled"
    ORDER_REJECTED = "order_rejected"
    POSITION_OPENED = "position_opened"
    POSITION_CLOSED = "position_closed"
    RISK_CHECK_PASSED = "risk_check_passed"
    RISK_CHECK_FAILED = "risk_check_failed"

class TradingLogger:
    """交易日志记录器

    专门用于记录交易相关的所有行为和状态变化
    """

    def __init__(self, log_manager: LogManager):
        self.log_manager = log_manager
        self.logger = log_manager.get_logger('trading')

        # 交易会话ID生成器
        self.session_counter = 0
        self.current_session = self._generate_session_id()

    def _generate_session_id(self) -> str:
        """生成交易会话ID"""
        self.session_counter += 1
        return f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{self.session_counter}"

    def log_signal_generation(self, strategy_name: str, stock_code: str,
                            signal_type: str, signal_strength: float,
                            trigger_conditions: Dict, market_data: Dict):
        """记录交易信号生成"""
        details = {
            'strategy_name': strategy_name,
            'stock_code': stock_code,
            'signal_type': signal_type,
            'signal_strength': signal_strength,
            'trigger_conditions': trigger_conditions,
            'market_data': {
                'price': market_data.get('last_price'),
                'volume': market_data.get('volume'),
                'timestamp': market_data.get('timestamp')
            },
            'session_id': self.current_session
        }

        self.log_manager.log_trading_action(
            TradingAction.SIGNAL_GENERATED.value,
            stock_code,
            details
        )

        self.logger.info(
            f"交易信号生成: {strategy_name} - {stock_code} - {signal_type} "
            f"(强度: {signal_strength:.2f})"
        )

    def log_order_creation(self, order_id: str, stock_code: str,
                          order_type: str, side: str, quantity: int,
                          price: float, strategy_name: str):
        """记录订单创建"""
        details = {
            'order_id': order_id,
            'stock_code': stock_code,
            'order_type': order_type,
            'side': side,
            'quantity': quantity,
            'price': price,
            'strategy_name': strategy_name,
            'session_id': self.current_session,
            'creation_time': datetime.now().isoformat()
        }

        self.log_manager.log_trading_action(
            TradingAction.ORDER_CREATED.value,
            stock_code,
            details
        )

        self.logger.info(
            f"订单创建: {order_id} - {stock_code} - {side} {quantity}@{price:.4f}"
        )

    def log_order_execution(self, order_id: str, stock_code: str,
                           execution_status: str, filled_quantity: int,
                           filled_price: float, commission: float,
                           execution_time: datetime):
        """记录订单执行"""
        details = {
            'order_id': order_id,
            'stock_code': stock_code,
            'execution_status': execution_status,
            'filled_quantity': filled_quantity,
            'filled_price': filled_price,
            'commission': commission,
            'execution_time': execution_time.isoformat(),
            'session_id': self.current_session
        }

        action = TradingAction.ORDER_FILLED if execution_status == 'FILLED' else TradingAction.ORDER_REJECTED
        level = 'info' if execution_status == 'FILLED' else 'warning'

        self.log_manager.log_trading_action(
            action.value,
            stock_code,
            details,
            level
        )

        self.logger.info(
            f"订单执行: {order_id} - {execution_status} - "
            f"{filled_quantity}@{filled_price:.4f} (手续费: {commission:.2f})"
        )

    def log_risk_check(self, stock_code: str, check_type: str,
                      check_result: bool, risk_details: Dict,
                      order_details: Optional[Dict] = None):
        """记录风控检查"""
        details = {
            'stock_code': stock_code,
            'check_type': check_type,
            'check_result': check_result,
            'risk_details': risk_details,
            'order_details': order_details or {},
            'session_id': self.current_session,
            'check_time': datetime.now().isoformat()
        }

        action = TradingAction.RISK_CHECK_PASSED if check_result else TradingAction.RISK_CHECK_FAILED
        level = 'info' if check_result else 'warning'

        self.log_manager.log_trading_action(
            action.value,
            stock_code,
            details,
            level
        )

        result_text = "通过" if check_result else "失败"
        self.logger.info(f"风控检查: {stock_code} - {check_type} - {result_text}")

    def log_position_change(self, stock_code: str, action: str,
                           quantity: int, price: float,
                           position_before: Dict, position_after: Dict):
        """记录持仓变化"""
        details = {
            'stock_code': stock_code,
            'action': action,
            'quantity': quantity,
            'price': price,
            'position_before': position_before,
            'position_after': position_after,
            'session_id': self.current_session,
            'change_time': datetime.now().isoformat()
        }

        trading_action = TradingAction.POSITION_OPENED if action == 'open' else TradingAction.POSITION_CLOSED

        self.log_manager.log_trading_action(
            trading_action.value,
            stock_code,
            details
        )

        self.logger.info(
            f"持仓变化: {stock_code} - {action} - {quantity}@{price:.4f}"
        )

    def log_trading_error(self, error_type: str, error_message: str,
                         context: Dict, exception: Optional[Exception] = None):
        """记录交易错误"""
        details = {
            'error_type': error_type,
            'error_message': error_message,
            'context': context,
            'session_id': self.current_session,
            'error_time': datetime.now().isoformat()
        }

        if exception:
            details['exception_type'] = type(exception).__name__
            details['exception_message'] = str(exception)

        self.logger.error(
            f"交易错误: {error_type} - {error_message}",
            extra={'extra_fields': details},
            exc_info=exception
        )

    def get_session_summary(self) -> Dict:
        """获取当前会话摘要"""
        # 这里可以从日志中统计当前会话的交易情况
        return {
            'session_id': self.current_session,
            'start_time': datetime.now().isoformat(),
            # 可以添加更多统计信息
        }


#### 3.2.3 DataFlowLogger - 数据流日志记录器
```python
from typing import Dict, Any, Optional
from datetime import datetime
import threading
from collections import defaultdict, deque

class DataFlowLogger:
    """数据流日志记录器

    专门用于记录数据在系统中的流转过程
    """

    def __init__(self, log_manager: LogManager):
        self.log_manager = log_manager
        self.logger = log_manager.get_logger('dataflow')

        # 数据流统计
        self.flow_stats = defaultdict(lambda: {
            'count': 0,
            'total_size': 0,
            'last_timestamp': None,
            'error_count': 0
        })

        # 数据流跟踪
        self.flow_traces = defaultdict(lambda: deque(maxlen=1000))

        # 线程锁
        self.stats_lock = threading.Lock()

    def log_data_received(self, data_type: str, stock_code: str,
                         data_size: int, source: str,
                         metadata: Optional[Dict] = None):
        """记录数据接收"""
        timestamp = datetime.now()

        details = {
            'data_type': data_type,
            'stock_code': stock_code,
            'data_size': data_size,
            'source': source,
            'metadata': metadata or {},
            'timestamp': timestamp.isoformat(),
            'flow_stage': 'received'
        }

        self.log_manager.log_data_flow(
            data_type, stock_code, 'received', details
        )

        # 更新统计
        with self.stats_lock:
            stats = self.flow_stats[f"{data_type}_{stock_code}"]
            stats['count'] += 1
            stats['total_size'] += data_size
            stats['last_timestamp'] = timestamp

        self.logger.debug(
            f"数据接收: {data_type} - {stock_code} - {data_size} bytes from {source}"
        )

    def log_data_processed(self, data_type: str, stock_code: str,
                          processing_stage: str, processing_time: float,
                          input_size: int, output_size: int,
                          metadata: Optional[Dict] = None):
        """记录数据处理"""
        details = {
            'data_type': data_type,
            'stock_code': stock_code,
            'processing_stage': processing_stage,
            'processing_time': processing_time,
            'input_size': input_size,
            'output_size': output_size,
            'metadata': metadata or {},
            'timestamp': datetime.now().isoformat(),
            'flow_stage': 'processed'
        }

        self.log_manager.log_data_flow(
            data_type, stock_code, 'processed', details
        )

        self.logger.debug(
            f"数据处理: {data_type} - {stock_code} - {processing_stage} "
            f"({processing_time:.2f}ms, {input_size}→{output_size} bytes)"
        )

    def log_data_stored(self, data_type: str, stock_code: str,
                       storage_type: str, storage_key: str,
                       data_size: int, ttl: Optional[int] = None):
        """记录数据存储"""
        details = {
            'data_type': data_type,
            'stock_code': stock_code,
            'storage_type': storage_type,
            'storage_key': storage_key,
            'data_size': data_size,
            'ttl': ttl,
            'timestamp': datetime.now().isoformat(),
            'flow_stage': 'stored'
        }

        self.log_manager.log_data_flow(
            data_type, stock_code, 'stored', details
        )

        self.logger.debug(
            f"数据存储: {data_type} - {stock_code} - {storage_type} "
            f"({data_size} bytes, TTL: {ttl})"
        )

    def log_data_retrieved(self, data_type: str, stock_code: str,
                          storage_type: str, storage_key: str,
                          data_size: int, cache_hit: bool):
        """记录数据检索"""
        details = {
            'data_type': data_type,
            'stock_code': stock_code,
            'storage_type': storage_type,
            'storage_key': storage_key,
            'data_size': data_size,
            'cache_hit': cache_hit,
            'timestamp': datetime.now().isoformat(),
            'flow_stage': 'retrieved'
        }

        self.log_manager.log_data_flow(
            data_type, stock_code, 'retrieved', details
        )

        hit_status = "命中" if cache_hit else "未命中"
        self.logger.debug(
            f"数据检索: {data_type} - {stock_code} - {storage_type} "
            f"({data_size} bytes, 缓存{hit_status})"
        )

    def log_data_error(self, data_type: str, stock_code: str,
                      error_stage: str, error_message: str,
                      error_context: Dict):
        """记录数据处理错误"""
        details = {
            'data_type': data_type,
            'stock_code': stock_code,
            'error_stage': error_stage,
            'error_message': error_message,
            'error_context': error_context,
            'timestamp': datetime.now().isoformat(),
            'flow_stage': 'error'
        }

        self.log_manager.log_data_flow(
            data_type, stock_code, 'error', details
        )

        # 更新错误统计
        with self.stats_lock:
            stats = self.flow_stats[f"{data_type}_{stock_code}"]
            stats['error_count'] += 1

        self.logger.error(
            f"数据流错误: {data_type} - {stock_code} - {error_stage} - {error_message}"
        )

    def log_data_flow_trace(self, trace_id: str, data_type: str,
                           stock_code: str, flow_path: List[str]):
        """记录数据流跟踪"""
        trace_info = {
            'trace_id': trace_id,
            'data_type': data_type,
            'stock_code': stock_code,
            'flow_path': flow_path,
            'timestamp': datetime.now().isoformat()
        }

        # 添加到跟踪队列
        self.flow_traces[trace_id].append(trace_info)

        self.logger.debug(
            f"数据流跟踪: {trace_id} - {data_type} - {stock_code} - "
            f"路径: {' → '.join(flow_path)}"
        )

    def get_flow_stats(self, data_type: Optional[str] = None,
                      stock_code: Optional[str] = None) -> Dict:
        """获取数据流统计"""
        with self.stats_lock:
            if data_type and stock_code:
                key = f"{data_type}_{stock_code}"
                return self.flow_stats.get(key, {}).copy()
            else:
                return {k: v.copy() for k, v in self.flow_stats.items()}

    def get_flow_trace(self, trace_id: str) -> List[Dict]:
        """获取数据流跟踪信息"""
        return list(self.flow_traces.get(trace_id, []))
```

## 4. 系统监控与配置管理

### 4.1 SystemMonitor - 系统监控器
```python
import psutil
import threading
import time
from typing import Dict, List, Optional, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

class AlertLevel(Enum):
    """告警级别"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class MonitorMetric:
    """监控指标"""
    name: str
    value: float
    threshold: float
    unit: str
    timestamp: datetime
    alert_level: AlertLevel = AlertLevel.INFO

class SystemMonitor:
    """系统监控器

    监控系统资源使用情况、性能指标和业务指标
    """

    def __init__(self, log_manager: LogManager, config: Dict):
        self.log_manager = log_manager
        self.config = config
        self.logger = log_manager.get_logger('monitor')

        # 监控指标存储
        self.metrics_history = {}
        self.current_metrics = {}

        # 告警回调函数
        self.alert_callbacks = []

        # 监控线程
        self.monitoring = False
        self.monitor_thread = None

        # 监控间隔
        self.monitor_interval = config.get('monitor_interval', 30)  # 30秒

        # 指标阈值配置
        self.thresholds = {
            'cpu_percent': config.get('cpu_threshold', 80.0),
            'memory_percent': config.get('memory_threshold', 85.0),
            'disk_percent': config.get('disk_threshold', 90.0),
            'network_error_rate': config.get('network_error_threshold', 0.01),
            'data_processing_latency': config.get('latency_threshold', 100.0),
            'error_rate': config.get('error_rate_threshold', 0.05)
        }

    def start_monitoring(self):
        """启动系统监控"""
        if self.monitoring:
            return

        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()

        self.logger.info("系统监控已启动")

    def stop_monitoring(self):
        """停止系统监控"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)

        self.logger.info("系统监控已停止")

    def _monitor_loop(self):
        """监控主循环"""
        while self.monitoring:
            try:
                # 收集系统指标
                self._collect_system_metrics()

                # 收集应用指标
                self._collect_application_metrics()

                # 检查告警条件
                self._check_alerts()

                # 记录监控日志
                self._log_metrics()

                time.sleep(self.monitor_interval)

            except Exception as e:
                self.logger.error(f"监控循环异常: {e}", exc_info=True)
                time.sleep(self.monitor_interval)

    def _collect_system_metrics(self):
        """收集系统资源指标"""
        timestamp = datetime.now()

        # CPU使用率
        cpu_percent = psutil.cpu_percent(interval=1)
        self._update_metric('cpu_percent', cpu_percent, '%', timestamp)

        # 内存使用率
        memory = psutil.virtual_memory()
        self._update_metric('memory_percent', memory.percent, '%', timestamp)
        self._update_metric('memory_used_gb', memory.used / (1024**3), 'GB', timestamp)

        # 磁盘使用率
        disk = psutil.disk_usage('/')
        disk_percent = (disk.used / disk.total) * 100
        self._update_metric('disk_percent', disk_percent, '%', timestamp)

        # 网络IO
        network = psutil.net_io_counters()
        self._update_metric('network_bytes_sent', network.bytes_sent, 'bytes', timestamp)
        self._update_metric('network_bytes_recv', network.bytes_recv, 'bytes', timestamp)

        # 进程信息
        process = psutil.Process()
        self._update_metric('process_cpu_percent', process.cpu_percent(), '%', timestamp)
        self._update_metric('process_memory_mb', process.memory_info().rss / (1024**2), 'MB', timestamp)
        self._update_metric('process_threads', process.num_threads(), 'count', timestamp)

    def _collect_application_metrics(self):
        """收集应用程序指标"""
        timestamp = datetime.now()

        # 从各个组件收集指标
        # 这里需要各个组件提供指标接口

        # 示例：数据处理指标
        # data_handler_stats = self.data_handler.get_stats()
        # self._update_metric('data_processed_count', data_handler_stats.get('processed_count', 0), 'count', timestamp)

        # 示例：数据库连接池指标
        # db_pool_stats = self.db_manager.get_pool_stats()
        # self._update_metric('db_active_connections', db_pool_stats.get('active', 0), 'count', timestamp)

    def _update_metric(self, name: str, value: float, unit: str, timestamp: datetime):
        """更新监控指标"""
        # 创建指标对象
        threshold = self.thresholds.get(name, float('inf'))
        alert_level = self._determine_alert_level(name, value, threshold)

        metric = MonitorMetric(
            name=name,
            value=value,
            threshold=threshold,
            unit=unit,
            timestamp=timestamp,
            alert_level=alert_level
        )

        # 更新当前指标
        self.current_metrics[name] = metric

        # 添加到历史记录
        if name not in self.metrics_history:
            self.metrics_history[name] = []

        self.metrics_history[name].append(metric)

        # 保持历史记录大小
        max_history = self.config.get('max_metric_history', 1000)
        if len(self.metrics_history[name]) > max_history:
            self.metrics_history[name] = self.metrics_history[name][-max_history:]

    def _determine_alert_level(self, name: str, value: float, threshold: float) -> AlertLevel:
        """确定告警级别"""
        if value >= threshold:
            if value >= threshold * 1.2:  # 超过阈值20%
                return AlertLevel.CRITICAL
            elif value >= threshold * 1.1:  # 超过阈值10%
                return AlertLevel.ERROR
            else:
                return AlertLevel.WARNING
        return AlertLevel.INFO

    def _check_alerts(self):
        """检查告警条件"""
        for name, metric in self.current_metrics.items():
            if metric.alert_level in [AlertLevel.WARNING, AlertLevel.ERROR, AlertLevel.CRITICAL]:
                self._trigger_alert(metric)

    def _trigger_alert(self, metric: MonitorMetric):
        """触发告警"""
        alert_message = (
            f"监控告警: {metric.name} = {metric.value:.2f}{metric.unit} "
            f"(阈值: {metric.threshold:.2f}{metric.unit})"
        )

        # 记录告警日志
        if metric.alert_level == AlertLevel.CRITICAL:
            self.logger.critical(alert_message)
        elif metric.alert_level == AlertLevel.ERROR:
            self.logger.error(alert_message)
        else:
            self.logger.warning(alert_message)

        # 调用告警回调
        for callback in self.alert_callbacks:
            try:
                callback(metric, alert_message)
            except Exception as e:
                self.logger.error(f"告警回调异常: {e}", exc_info=True)

    def _log_metrics(self):
        """记录监控指标日志"""
        # 每分钟记录一次详细指标
        if datetime.now().second == 0:
            metrics_summary = {}
            for name, metric in self.current_metrics.items():
                metrics_summary[name] = {
                    'value': metric.value,
                    'unit': metric.unit,
                    'alert_level': metric.alert_level.value
                }

            self.logger.info(
                "系统监控指标摘要",
                extra={'extra_fields': {'metrics': metrics_summary}}
            )

    def add_alert_callback(self, callback: Callable[[MonitorMetric, str], None]):
        """添加告警回调函数"""
        self.alert_callbacks.append(callback)

    def get_current_metrics(self) -> Dict[str, MonitorMetric]:
        """获取当前监控指标"""
        return self.current_metrics.copy()

    def get_metric_history(self, metric_name: str,
                          start_time: Optional[datetime] = None,
                          end_time: Optional[datetime] = None) -> List[MonitorMetric]:
        """获取指标历史数据"""
        if metric_name not in self.metrics_history:
            return []

        history = self.metrics_history[metric_name]

        if start_time or end_time:
            filtered_history = []
            for metric in history:
                if start_time and metric.timestamp < start_time:
                    continue
                if end_time and metric.timestamp > end_time:
                    continue
                filtered_history.append(metric)
            return filtered_history

        return history.copy()

    def get_system_health_summary(self) -> Dict:
        """获取系统健康状况摘要"""
        summary = {
            'overall_status': 'healthy',
            'critical_alerts': 0,
            'error_alerts': 0,
            'warning_alerts': 0,
            'key_metrics': {},
            'last_update': datetime.now().isoformat()
        }

        for name, metric in self.current_metrics.items():
            if metric.alert_level == AlertLevel.CRITICAL:
                summary['critical_alerts'] += 1
                summary['overall_status'] = 'critical'
            elif metric.alert_level == AlertLevel.ERROR:
                summary['error_alerts'] += 1
                if summary['overall_status'] == 'healthy':
                    summary['overall_status'] = 'error'
            elif metric.alert_level == AlertLevel.WARNING:
                summary['warning_alerts'] += 1
                if summary['overall_status'] == 'healthy':
                    summary['overall_status'] = 'warning'

            # 记录关键指标
            if name in ['cpu_percent', 'memory_percent', 'disk_percent']:
                summary['key_metrics'][name] = {
                    'value': metric.value,
                    'unit': metric.unit,
                    'status': metric.alert_level.value
                }

        return summary


### 4.2 ConfigManager - 配置管理器
```python
import yaml
import json
import threading
from typing import Dict, Any, Optional, List, Callable
from datetime import datetime
from pathlib import Path
import hashlib

class ConfigManager:
    """配置管理器

    提供配置文件管理、热更新、版本控制等功能
    """

    def __init__(self, config_file: str, log_manager: LogManager):
        self.config_file = Path(config_file)
        self.log_manager = log_manager
        self.logger = log_manager.get_logger('config')

        # 配置数据
        self.config_data = {}
        self.config_lock = threading.RLock()

        # 配置变更回调
        self.change_callbacks = {}

        # 配置版本管理
        self.config_versions = []
        self.current_version = None

        # 文件监控
        self.file_monitor_thread = None
        self.monitoring = False
        self.last_modified = None

        # 加载初始配置
        self.load_config()

        # 启动文件监控
        self.start_file_monitoring()

    def load_config(self) -> bool:
        """加载配置文件"""
        try:
            if not self.config_file.exists():
                self.logger.error(f"配置文件不存在: {self.config_file}")
                return False

            with open(self.config_file, 'r', encoding='utf-8') as f:
                if self.config_file.suffix.lower() == '.yaml' or self.config_file.suffix.lower() == '.yml':
                    new_config = yaml.safe_load(f)
                else:
                    new_config = json.load(f)

            # 验证配置
            if not self._validate_config(new_config):
                self.logger.error("配置文件验证失败")
                return False

            with self.config_lock:
                old_config = self.config_data.copy()
                self.config_data = new_config

                # 记录配置版本
                config_hash = self._calculate_config_hash(new_config)
                version_info = {
                    'version': config_hash,
                    'timestamp': datetime.now(),
                    'file_path': str(self.config_file),
                    'size': self.config_file.stat().st_size
                }

                self.config_versions.append(version_info)
                self.current_version = config_hash

                # 保持版本历史大小
                if len(self.config_versions) > 50:
                    self.config_versions = self.config_versions[-50:]

            # 检测配置变更
            changes = self._detect_changes(old_config, new_config)
            if changes:
                self._notify_config_changes(changes)

            self.logger.info(f"配置文件加载成功: {self.config_file}")
            return True

        except Exception as e:
            self.logger.error(f"加载配置文件异常: {e}", exc_info=True)
            return False

    def get(self, key: str, default: Any = None) -> Any:
        """获取配置值"""
        with self.config_lock:
            keys = key.split('.')
            value = self.config_data

            try:
                for k in keys:
                    value = value[k]
                return value
            except (KeyError, TypeError):
                return default

    def set(self, key: str, value: Any, save_to_file: bool = True) -> bool:
        """设置配置值"""
        try:
            with self.config_lock:
                keys = key.split('.')
                config = self.config_data

                # 导航到目标位置
                for k in keys[:-1]:
                    if k not in config:
                        config[k] = {}
                    config = config[k]

                # 设置值
                old_value = config.get(keys[-1])
                config[keys[-1]] = value

                # 保存到文件
                if save_to_file:
                    self._save_config_to_file()

                # 通知变更
                changes = {key: {'old': old_value, 'new': value}}
                self._notify_config_changes(changes)

            self.logger.info(f"配置更新: {key} = {value}")
            return True

        except Exception as e:
            self.logger.error(f"设置配置值异常: {e}", exc_info=True)
            return False

    def _save_config_to_file(self):
        """保存配置到文件"""
        try:
            # 创建备份
            backup_file = self.config_file.with_suffix(f'.backup.{datetime.now().strftime("%Y%m%d_%H%M%S")}')
            if self.config_file.exists():
                backup_file.write_text(self.config_file.read_text(encoding='utf-8'), encoding='utf-8')

            # 保存新配置
            with open(self.config_file, 'w', encoding='utf-8') as f:
                if self.config_file.suffix.lower() in ['.yaml', '.yml']:
                    yaml.dump(self.config_data, f, default_flow_style=False, allow_unicode=True)
                else:
                    json.dump(self.config_data, f, indent=2, ensure_ascii=False)

            self.logger.info(f"配置已保存到文件: {self.config_file}")

        except Exception as e:
            self.logger.error(f"保存配置文件异常: {e}", exc_info=True)

    def _validate_config(self, config: Dict) -> bool:
        """验证配置文件"""
        # 这里可以添加配置验证逻辑
        # 例如检查必需的配置项、数据类型等

        required_keys = [
            'database.host',
            'database.port',
            'redis.host',
            'redis.port'
        ]

        for key in required_keys:
            if self._get_nested_value(config, key) is None:
                self.logger.error(f"缺少必需的配置项: {key}")
                return False

        return True

    def _get_nested_value(self, data: Dict, key: str) -> Any:
        """获取嵌套字典的值"""
        keys = key.split('.')
        value = data

        try:
            for k in keys:
                value = value[k]
            return value
        except (KeyError, TypeError):
            return None

    def _calculate_config_hash(self, config: Dict) -> str:
        """计算配置哈希值"""
        config_str = json.dumps(config, sort_keys=True)
        return hashlib.md5(config_str.encode()).hexdigest()

    def _detect_changes(self, old_config: Dict, new_config: Dict) -> Dict:
        """检测配置变更"""
        changes = {}

        def compare_dict(old_dict, new_dict, prefix=''):
            for key, new_value in new_dict.items():
                full_key = f"{prefix}.{key}" if prefix else key
                old_value = old_dict.get(key)

                if isinstance(new_value, dict) and isinstance(old_value, dict):
                    compare_dict(old_value, new_value, full_key)
                elif old_value != new_value:
                    changes[full_key] = {'old': old_value, 'new': new_value}

            # 检查删除的键
            for key, old_value in old_dict.items():
                if key not in new_dict:
                    full_key = f"{prefix}.{key}" if prefix else key
                    changes[full_key] = {'old': old_value, 'new': None}

        compare_dict(old_config, new_config)
        return changes

    def _notify_config_changes(self, changes: Dict):
        """通知配置变更"""
        for key, change in changes.items():
            self.logger.info(
                f"配置变更: {key} {change['old']} -> {change['new']}"
            )

            # 调用注册的回调函数
            for pattern, callback in self.change_callbacks.items():
                if key.startswith(pattern) or pattern == '*':
                    try:
                        callback(key, change['old'], change['new'])
                    except Exception as e:
                        self.logger.error(f"配置变更回调异常: {e}", exc_info=True)

    def register_change_callback(self, key_pattern: str, callback: Callable):
        """注册配置变更回调"""
        self.change_callbacks[key_pattern] = callback
        self.logger.info(f"注册配置变更回调: {key_pattern}")

    def start_file_monitoring(self):
        """启动文件监控"""
        if self.monitoring:
            return

        self.monitoring = True
        self.file_monitor_thread = threading.Thread(target=self._file_monitor_loop, daemon=True)
        self.file_monitor_thread.start()

        self.logger.info("配置文件监控已启动")

    def _file_monitor_loop(self):
        """文件监控循环"""
        while self.monitoring:
            try:
                if self.config_file.exists():
                    current_modified = self.config_file.stat().st_mtime

                    if self.last_modified is None:
                        self.last_modified = current_modified
                    elif current_modified > self.last_modified:
                        self.logger.info("检测到配置文件变更，重新加载")
                        self.load_config()
                        self.last_modified = current_modified

                time.sleep(5)  # 每5秒检查一次

            except Exception as e:
                self.logger.error(f"文件监控异常: {e}", exc_info=True)
                time.sleep(10)

    def get_config_info(self) -> Dict:
        """获取配置信息"""
        with self.config_lock:
            return {
                'current_version': self.current_version,
                'file_path': str(self.config_file),
                'last_modified': self.last_modified,
                'version_count': len(self.config_versions),
                'config_size': len(str(self.config_data))
            }

    def shutdown(self):
        """关闭配置管理器"""
        self.monitoring = False
        if self.file_monitor_thread:
            self.file_monitor_thread.join(timeout=5)

        self.logger.info("配置管理器已关闭")
```

## 5. 关键算法实现

### 5.1 MainFundCalculator - 主力资金计算器
```python
import logging
from typing import Dict, List, Tuple
from datetime import datetime
from dataclasses import dataclass

@dataclass
class FundFlowResult:
    """资金流向计算结果"""
    main_inflow: float      # 主力流入
    main_outflow: float     # 主力流出
    main_net: float         # 主力净额
    main_net_ratio: float   # 主力净比
    large_order_count: int  # 大单数量
    total_amount: float     # 总成交额
    calculation_time: datetime

class MainFundCalculator:
    """主力资金计算器

    基于逐笔成交数据计算主力资金流向
    """

    def __init__(self, config_manager: 'ConfigManager', log_manager: LogManager):
        self.config_manager = config_manager
        self.logger = log_manager.get_logger('fund_calculator')

        # 大单阈值配置
        self.large_order_thresholds = {
            'volume_threshold': config_manager.get('fund_calculator.volume_threshold', 50000),
            'amount_threshold': config_manager.get('fund_calculator.amount_threshold', 1000000),
            'super_large_threshold': config_manager.get('fund_calculator.super_large_threshold', 5000000)
        }

    def calculate_fund_flow(self, transactions: List[Dict],
                           time_window: int = 300) -> FundFlowResult:
        """计算主力资金流向

        Args:
            transactions: 逐笔成交数据列表
            time_window: 时间窗口（秒）

        Returns:
            FundFlowResult: 资金流向计算结果
        """
        try:
            start_time = datetime.now()

            # 过滤时间窗口内的数据
            filtered_transactions = self._filter_by_time_window(transactions, time_window)

            main_inflow = 0.0
            main_outflow = 0.0
            total_amount = 0.0
            large_order_count = 0

            for trans in filtered_transactions:
                # 计算成交金额
                amount = trans['trade_price'] * trans['trade_volume']
                total_amount += amount

                # 判断是否为大单
                if self._is_large_order(trans):
                    large_order_count += 1

                    # 判断买卖方向
                    if self._is_buy_order(trans):
                        main_inflow += amount
                    else:
                        main_outflow += amount

            # 计算主力净额和净比
            main_net = main_inflow - main_outflow
            main_net_ratio = (main_net / total_amount * 100) if total_amount > 0 else 0

            result = FundFlowResult(
                main_inflow=main_inflow,
                main_outflow=main_outflow,
                main_net=main_net,
                main_net_ratio=main_net_ratio,
                large_order_count=large_order_count,
                total_amount=total_amount,
                calculation_time=datetime.now()
            )

            # 记录计算日志
            calculation_time = (datetime.now() - start_time).total_seconds() * 1000
            self.logger.debug(
                f"主力资金计算完成: 净额 {main_net:.2f}, 净比 {main_net_ratio:.2f}%, "
                f"大单 {large_order_count} 笔, 耗时 {calculation_time:.2f}ms"
            )

            return result

        except Exception as e:
            self.logger.error(f"计算主力资金流向异常: {e}", exc_info=True)
            return FundFlowResult(0, 0, 0, 0, 0, 0, datetime.now())

    def _filter_by_time_window(self, transactions: List[Dict],
                              time_window: int) -> List[Dict]:
        """按时间窗口过滤交易数据"""
        if not transactions:
            return []

        # 获取最新时间
        latest_time = max(trans['trade_time'] for trans in transactions)
        cutoff_time = latest_time - time_window * 1000  # 转换为毫秒

        return [trans for trans in transactions if trans['trade_time'] >= cutoff_time]

    def _is_large_order(self, transaction: Dict) -> bool:
        """判断是否为大单"""
        volume = transaction['trade_volume']
        amount = transaction['trade_price'] * volume

        # 基于成交量判断
        if volume >= self.large_order_thresholds['volume_threshold']:
            return True

        # 基于成交金额判断
        if amount >= self.large_order_thresholds['amount_threshold']:
            return True

        return False

    def _is_buy_order(self, transaction: Dict) -> bool:
        """判断是否为买单

        基于TradeBSFlag字段判断：
        'B' - 买入
        'S' - 卖出
        '4' - 撤单
        """
        trade_bs_flag = transaction.get('trade_bs_flag', '')

        if trade_bs_flag == 'B':
            return True
        elif trade_bs_flag == 'S':
            return False
        else:
            # 对于无法确定方向的交易，使用价格判断
            # 如果成交价接近卖一价，认为是买入
            # 如果成交价接近买一价，认为是卖出
            return self._infer_direction_by_price(transaction)

    def _infer_direction_by_price(self, transaction: Dict) -> bool:
        """通过价格推断买卖方向"""
        # 这里需要结合当时的盘口数据来判断
        # 简化实现：随机返回（实际应该基于盘口数据）
        return True  # 默认认为是买入


### 5.2 LimitUpDetector - 涨停检测器
```python
from typing import Dict, List, Optional, Tuple
from datetime import datetime, time
from dataclasses import dataclass

@dataclass
class LimitUpInfo:
    """涨停信息"""
    stock_code: str
    first_limit_up_time: Optional[datetime]
    break_count: int
    reseal_count: int
    final_sealed: bool
    max_break_duration: int  # 最长炸板持续时间（秒）
    seal_strength: float     # 封单强度
    limit_up_price: float

class LimitUpDetector:
    """涨停检测器

    检测股票的涨停时间、炸板次数、回封情况等
    """

    def __init__(self, config_manager: 'ConfigManager', log_manager: LogManager):
        self.config_manager = config_manager
        self.logger = log_manager.get_logger('limit_up_detector')

        # 涨停检测配置
        self.price_tolerance = config_manager.get('limit_up.price_tolerance', 0.01)
        self.min_seal_duration = config_manager.get('limit_up.min_seal_duration', 30)  # 30秒

    def detect_limit_up_pattern(self, stock_code: str,
                               market_data_list: List[Dict],
                               order_data_list: List[Dict] = None) -> LimitUpInfo:
        """检测涨停模式

        Args:
            stock_code: 股票代码
            market_data_list: 按时间排序的行情数据
            order_data_list: 逐笔委托数据（可选）

        Returns:
            LimitUpInfo: 涨停信息
        """
        try:
            if not market_data_list:
                return self._empty_limit_up_info(stock_code)

            # 计算涨停价
            first_data = market_data_list[0]
            prev_close = first_data.get('pre_close_price', 0)
            limit_up_price = prev_close * 1.1  # 10%涨停

            # 检测涨停时间点
            limit_up_times = []
            break_times = []
            current_state = 'normal'  # normal, limit_up
            state_start_time = None

            for i, data in enumerate(market_data_list):
                current_price = data['last_price']
                timestamp = data['timestamp']

                # 判断是否涨停
                is_limit_up = abs(current_price - limit_up_price) <= self.price_tolerance

                if is_limit_up and current_state == 'normal':
                    # 进入涨停状态
                    current_state = 'limit_up'
                    state_start_time = timestamp
                    limit_up_times.append(timestamp)

                elif not is_limit_up and current_state == 'limit_up':
                    # 炸板
                    current_state = 'normal'
                    if state_start_time:
                        break_duration = timestamp - state_start_time
                        break_times.append({
                            'start_time': state_start_time,
                            'end_time': timestamp,
                            'duration': break_duration
                        })
                    state_start_time = timestamp

            # 计算统计信息
            first_limit_up_time = limit_up_times[0] if limit_up_times else None
            break_count = len(break_times)
            reseal_count = max(0, len(limit_up_times) - 1)
            final_sealed = current_state == 'limit_up'
            max_break_duration = max([bt['duration'] for bt in break_times], default=0)

            # 计算封单强度
            seal_strength = self._calculate_seal_strength(
                market_data_list, order_data_list, limit_up_price
            )

            result = LimitUpInfo(
                stock_code=stock_code,
                first_limit_up_time=first_limit_up_time,
                break_count=break_count,
                reseal_count=reseal_count,
                final_sealed=final_sealed,
                max_break_duration=max_break_duration,
                seal_strength=seal_strength,
                limit_up_price=limit_up_price
            )

            self.logger.debug(
                f"涨停检测完成: {stock_code} - 首次涨停 {first_limit_up_time}, "
                f"炸板 {break_count} 次, 回封 {reseal_count} 次"
            )

            return result

        except Exception as e:
            self.logger.error(f"检测涨停模式异常: {e}", exc_info=True)
            return self._empty_limit_up_info(stock_code)

    def _calculate_seal_strength(self, market_data_list: List[Dict],
                                order_data_list: Optional[List[Dict]],
                                limit_up_price: float) -> float:
        """计算封单强度"""
        if not order_data_list:
            return 0.0

        try:
            # 统计涨停价位的买单委托量
            total_buy_volume = 0
            total_sell_volume = 0

            for order in order_data_list:
                if abs(order['price'] - limit_up_price) <= self.price_tolerance:
                    if order['side'] == 'B':  # 买单
                        total_buy_volume += order['volume']
                    elif order['side'] == 'S':  # 卖单
                        total_sell_volume += order['volume']

            # 封单强度 = 买单量 / (买单量 + 卖单量)
            total_volume = total_buy_volume + total_sell_volume
            if total_volume > 0:
                return total_buy_volume / total_volume
            else:
                return 0.0

        except Exception as e:
            self.logger.error(f"计算封单强度异常: {e}", exc_info=True)
            return 0.0

    def _empty_limit_up_info(self, stock_code: str) -> LimitUpInfo:
        """返回空的涨停信息"""
        return LimitUpInfo(
            stock_code=stock_code,
            first_limit_up_time=None,
            break_count=0,
            reseal_count=0,
            final_sealed=False,
            max_break_duration=0,
            seal_strength=0.0,
            limit_up_price=0.0
        )

    def is_limit_up_time_valid(self, limit_up_time: datetime) -> Tuple[bool, str]:
        """判断涨停时间是否符合策略要求"""
        if not limit_up_time:
            return False, "无涨停时间"

        # 获取涨停时间（只考虑时分秒）
        limit_time = limit_up_time.time()

        # 定义时间段
        morning_start = time(9, 30)   # 9:30
        morning_end = time(11, 30)    # 11:30
        afternoon_start = time(13, 0) # 13:00
        afternoon_end = time(15, 0)   # 15:00

        # 早盘涨停
        if morning_start <= limit_time <= morning_end:
            if limit_time <= time(10, 0):
                return True, "早盘早期涨停"
            else:
                return True, "早盘后期涨停"

        # 午盘涨停
        elif afternoon_start <= limit_time <= afternoon_end:
            if limit_time >= time(14, 0):
                return True, "午盘后期涨停"
            else:
                return True, "午盘前期涨停"

        else:
            return False, "非交易时间涨停"


### 5.3 数据验证器
```python
from typing import Dict, List, Optional, Any
from datetime import datetime
import re

class DataValidator:
    """数据验证器

    验证Level2数据的完整性和合理性
    """

    def __init__(self, config: Dict):
        self.config = config
        self.stock_code_pattern = re.compile(r'^[0-9]{6}$')

        # 价格合理性范围
        self.price_range = {
            'min_price': 0.01,
            'max_price': 10000.0
        }

        # 成交量合理性范围
        self.volume_range = {
            'min_volume': 0,
            'max_volume': 1000000000  # 10亿股
        }

    def validate_market_data(self, data: Dict) -> bool:
        """验证快照行情数据"""
        try:
            # 检查必需字段
            required_fields = [
                'stock_code', 'last_price', 'volume', 'amount',
                'bid_prices', 'ask_prices', 'bid_volumes', 'ask_volumes'
            ]

            for field in required_fields:
                if field not in data or data[field] is None:
                    return False

            # 验证股票代码
            if not self.stock_code_pattern.match(data['stock_code']):
                return False

            # 验证价格合理性
            if not self._validate_price(data['last_price']):
                return False

            # 验证成交量
            if not self._validate_volume(data['volume']):
                return False

            # 验证盘口数据
            if not self._validate_order_book(data['bid_prices'], data['ask_prices']):
                return False

            return True

        except Exception:
            return False

    def validate_transaction_data(self, data: Dict) -> bool:
        """验证逐笔成交数据"""
        try:
            required_fields = [
                'stock_code', 'trade_price', 'trade_volume', 'trade_time'
            ]

            for field in required_fields:
                if field not in data or data[field] is None:
                    return False

            # 验证股票代码
            if not self.stock_code_pattern.match(data['stock_code']):
                return False

            # 验证价格和成交量
            if not self._validate_price(data['trade_price']):
                return False

            if not self._validate_volume(data['trade_volume']):
                return False

            return True

        except Exception:
            return False

    def validate_order_data(self, data: Dict) -> bool:
        """验证逐笔委托数据"""
        try:
            required_fields = [
                'stock_code', 'price', 'volume', 'side', 'order_time'
            ]

            for field in required_fields:
                if field not in data or data[field] is None:
                    return False

            # 验证股票代码
            if not self.stock_code_pattern.match(data['stock_code']):
                return False

            # 验证价格和委托量
            if not self._validate_price(data['price']):
                return False

            if not self._validate_volume(data['volume']):
                return False

            # 验证买卖方向
            if data['side'] not in ['B', 'S']:
                return False

            return True

        except Exception:
            return False

    def _validate_price(self, price: float) -> bool:
        """验证价格合理性"""
        return (self.price_range['min_price'] <= price <= self.price_range['max_price']
                and not (price != price))  # 检查NaN

    def _validate_volume(self, volume: int) -> bool:
        """验证成交量合理性"""
        return (self.volume_range['min_volume'] <= volume <= self.volume_range['max_volume']
                and isinstance(volume, (int, float)))

    def _validate_order_book(self, bid_prices: List[float],
                           ask_prices: List[float]) -> bool:
        """验证盘口数据合理性"""
        try:
            # 检查价格递减/递增顺序
            for i in range(1, len(bid_prices)):
                if bid_prices[i] > bid_prices[i-1]:  # 买价应该递减
                    return False

            for i in range(1, len(ask_prices)):
                if ask_prices[i] < ask_prices[i-1]:  # 卖价应该递增
                    return False

            # 检查买卖价差合理性
            if bid_prices[0] > 0 and ask_prices[0] > 0:
                if bid_prices[0] >= ask_prices[0]:  # 买一价不应该大于等于卖一价
                    return False

            return True

        except Exception:
            return False
```

## 6. 部署配置与运行环境

### 6.1 系统配置文件示例
```yaml
# config.yaml - 主配置文件
system:
  name: "股票自动交易系统"
  version: "1.0.0"
  environment: "production"  # development/testing/production

# Level2 API配置
level2_api:
  connection_type: "tcp"  # tcp/udp
  tcp_address: "tcp://127.0.0.1:9001"
  multicast_address: "233.50.50.50:9001"
  interface_ip: "192.168.1.100"
  login_account: "your_account"
  password: "your_password"
  cache_mode: false

  # 订阅配置
  subscriptions:
    market_data: true
    transaction: true
    order_detail: true
    securities: ["000001", "000002", "300001"]
    exchange: "COMM"  # COMM/SSE/SZSE

# 数据库配置
database:
  postgresql:
    host: "localhost"
    port: 5432
    database: "trading_system"
    username: "postgres"
    password: "password"
    pool_size: 20
    max_overflow: 30
    pool_timeout: 30

  redis:
    host: "localhost"
    port: 6379
    password: ""
    db: 0
    max_connections: 50

  influxdb:
    host: "localhost"
    port: 8086
    database: "market_data"
    username: "admin"
    password: "password"
    retention_policy: "30d"

# 日志配置
logging:
  log_dir: "./logs"
  max_file_size: 104857600  # 100MB
  backup_count: 10
  log_retention_days: 30

  levels:
    root: "INFO"
    trading_system: "DEBUG"
    trading_system.dataflow: "DEBUG"
    trading_system.trading: "INFO"
    trading_system.strategy: "INFO"

# 性能配置
performance:
  data_handler:
    batch_size: 100
    batch_timeout: 1.0
    worker_threads: 4
    max_queue_size: 10000

  score_engine:
    max_workers: 8
    batch_size: 100

  strategy_engine:
    parallel_execution: true
    max_concurrent_strategies: 3

# 监控配置
monitoring:
  enabled: true
  monitor_interval: 30
  cpu_threshold: 80.0
  memory_threshold: 85.0
  disk_threshold: 90.0
  network_error_threshold: 0.01
  latency_threshold: 100.0
  error_rate_threshold: 0.05

# 评分器配置
scorers:
  limitupbreakscorer:
    x1_percent: 1.0

  declinescorer:
    x2_percent: 1.0
    decline_threshold: -0.02

  limitupsealscore:
    seal_threshold: 30000000  # 3000万
    score_value: 2.0

  limituptimescorer:
    morning_score: 3.0
    afternoon_score: 5.0

  continuousdeclinescorer:
    x3_percent: 1.0
    decline_threshold: -0.02

  limitupresealscorer:
    reseal_threshold: 5
    score_value: 5.0

# 策略配置
strategies:
  pool_a:
    market_value_min: 50  # 50亿
    market_value_max: 400  # 400亿
    auction_amount_min: 10000000  # 1000万
    turnover_rate_min: 0.002  # 0.2%
    price_change_min: -0.02  # -2%
    amount_ratio_min: 1.0  # 100%

  pool_b:
    top_count: 20
    market_value_min: 50
    market_value_max: 400
    auction_amount_min: 1000000  # 100万
    turnover_rate_min: 0.002
    price_change_min: -0.02
    amount_ratio_min: 1.0

  pool_zb:
    seal_amount_min: 30000000  # 3000万
    zb_a:
      market_value_min: 400
      market_value_max: 5000
    zb_b:
      market_value_min: 50
      market_value_max: 400

# 风控配置
risk_control:
  max_position_ratio: 0.1  # 单股最大持仓比例10%
  max_total_position: 0.8  # 总持仓比例80%
  max_daily_trades: 100    # 日内最大交易次数
  min_account_balance: 100000  # 最小账户余额

# 主力资金计算配置
fund_calculator:
  volume_threshold: 50000      # 5万股
  amount_threshold: 1000000    # 100万元
  super_large_threshold: 5000000  # 500万元

# 涨停检测配置
limit_up:
  price_tolerance: 0.01        # 价格容差
  min_seal_duration: 30        # 最小封板持续时间（秒）
```

### 6.2 启动脚本
```python
#!/usr/bin/env python3
# main.py - 系统启动脚本

import asyncio
import signal
import sys
import yaml
from pathlib import Path
from typing import Dict, Any

from trading_system.core.log_manager import LogManager
from trading_system.core.config_manager import ConfigManager
from trading_system.core.system_monitor import SystemMonitor
from trading_system.data.market_data_receiver import MarketDataReceiver
from trading_system.data.data_handler import DataHandler
from trading_system.data.database_manager import DatabaseManager
from trading_system.data.cache_manager import CacheManager
from trading_system.engine.historical_score_engine import HistoricalScoreEngine
from trading_system.engine.strategy_engine import StrategyEngine

class TradingSystemApplication:
    """股票自动交易系统主应用"""

    def __init__(self, config_file: str):
        self.config_file = config_file
        self.running = False

        # 核心组件
        self.log_manager = None
        self.config_manager = None
        self.system_monitor = None
        self.db_manager = None
        self.cache_manager = None
        self.data_handler = None
        self.market_data_receiver = None
        self.score_engine = None
        self.strategy_engine = None

        # 日志记录器
        self.logger = None

    async def initialize(self) -> bool:
        """初始化系统"""
        try:
            print("正在初始化股票自动交易系统...")

            # 1. 初始化配置管理器
            self.config_manager = ConfigManager(self.config_file, None)
            config_data = self.config_manager.config_data

            # 2. 初始化日志管理器
            self.log_manager = LogManager(config_data.get('logging', {}))
            self.logger = self.log_manager.get_logger('application')

            # 更新配置管理器的日志管理器
            self.config_manager.log_manager = self.log_manager

            self.logger.info("开始初始化股票自动交易系统")

            # 3. 初始化系统监控
            self.system_monitor = SystemMonitor(
                self.log_manager,
                config_data.get('monitoring', {})
            )

            # 4. 初始化数据库管理器
            self.db_manager = DatabaseManager(
                config_data.get('database', {}),
                self.log_manager
            )
            await self.db_manager.initialize()

            # 5. 初始化缓存管理器
            self.cache_manager = CacheManager(
                config_data.get('database', {}).get('redis', {}),
                self.log_manager
            )
            await self.cache_manager.initialize()

            # 6. 初始化数据处理器
            self.data_handler = DataHandler(
                self.db_manager,
                self.cache_manager,
                config_data.get('performance', {}).get('data_handler', {})
            )
            await self.data_handler.start_processing()

            # 7. 初始化Level2数据接收器
            self.market_data_receiver = MarketDataReceiver(
                config_data.get('level2_api', {}),
                self.data_handler
            )

            # 8. 初始化历史评分引擎
            self.score_engine = HistoricalScoreEngine(
                self.db_manager,
                self.config_manager
            )

            # 9. 初始化策略引擎
            self.strategy_engine = StrategyEngine(
                self.db_manager,
                self.cache_manager,
                self.config_manager,
                self.log_manager
            )

            # 10. 启动系统监控
            self.system_monitor.start_monitoring()

            self.logger.info("股票自动交易系统初始化完成")
            return True

        except Exception as e:
            if self.logger:
                self.logger.error(f"系统初始化失败: {e}", exc_info=True)
            else:
                print(f"系统初始化失败: {e}")
            return False

    async def start(self) -> bool:
        """启动系统"""
        try:
            self.logger.info("正在启动股票自动交易系统...")

            # 启动Level2数据接收
            if not self.market_data_receiver.initialize():
                self.logger.error("Level2数据接收器启动失败")
                return False

            # 启动策略引擎
            await self.strategy_engine.start()

            self.running = True
            self.logger.info("股票自动交易系统启动成功")

            return True

        except Exception as e:
            self.logger.error(f"系统启动失败: {e}", exc_info=True)
            return False

    async def run(self):
        """运行系统主循环"""
        self.logger.info("系统进入运行状态")

        try:
            while self.running:
                # 系统主循环
                await asyncio.sleep(1)

                # 这里可以添加定期任务
                # 例如：健康检查、统计报告等

        except KeyboardInterrupt:
            self.logger.info("接收到中断信号，准备关闭系统")
        except Exception as e:
            self.logger.error(f"系统运行异常: {e}", exc_info=True)

    async def shutdown(self):
        """关闭系统"""
        self.logger.info("正在关闭股票自动交易系统...")

        self.running = False

        try:
            # 按相反顺序关闭组件
            if self.market_data_receiver:
                self.market_data_receiver.shutdown()

            if self.strategy_engine:
                await self.strategy_engine.shutdown()

            if self.data_handler:
                await self.data_handler.shutdown()

            if self.score_engine:
                self.score_engine.shutdown()

            if self.cache_manager:
                await self.cache_manager.shutdown()

            if self.db_manager:
                await self.db_manager.shutdown()

            if self.system_monitor:
                self.system_monitor.stop_monitoring()

            if self.config_manager:
                self.config_manager.shutdown()

            if self.log_manager:
                self.log_manager.shutdown()

            self.logger.info("股票自动交易系统已关闭")

        except Exception as e:
            print(f"系统关闭异常: {e}")


async def main():
    """主函数"""
    # 配置文件路径
    config_file = sys.argv[1] if len(sys.argv) > 1 else "config.yaml"

    if not Path(config_file).exists():
        print(f"配置文件不存在: {config_file}")
        sys.exit(1)

    # 创建应用实例
    app = TradingSystemApplication(config_file)

    # 设置信号处理
    def signal_handler(signum, frame):
        print(f"\n接收到信号 {signum}，准备关闭系统...")
        asyncio.create_task(app.shutdown())

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        # 初始化系统
        if not await app.initialize():
            print("系统初始化失败")
            sys.exit(1)

        # 启动系统
        if not await app.start():
            print("系统启动失败")
            sys.exit(1)

        # 运行系统
        await app.run()

    except Exception as e:
        print(f"系统运行异常: {e}")
        sys.exit(1)

    finally:
        # 确保系统正确关闭
        await app.shutdown()


if __name__ == "__main__":
    asyncio.run(main())
```

### 6.3 Docker部署配置
```dockerfile
# Dockerfile
FROM python:3.9-slim

# 设置工作目录
WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .

# 安装Python依赖
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 创建日志目录
RUN mkdir -p /app/logs

# 设置环境变量
ENV PYTHONPATH=/app
ENV TZ=Asia/Shanghai

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["python", "main.py", "config.yaml"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  trading-system:
    build: .
    container_name: trading-system
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - ./logs:/app/logs
      - ./config:/app/config
      - ./data:/app/data
    environment:
      - PYTHONPATH=/app
      - TZ=Asia/Shanghai
    depends_on:
      - postgres
      - redis
      - influxdb
    networks:
      - trading-network

  postgres:
    image: postgres:13
    container_name: trading-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=trading_system
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - trading-network

  redis:
    image: redis:6-alpine
    container_name: trading-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - trading-network

  influxdb:
    image: influxdb:1.8
    container_name: trading-influxdb
    restart: unless-stopped
    environment:
      - INFLUXDB_DB=market_data
      - INFLUXDB_ADMIN_USER=admin
      - INFLUXDB_ADMIN_PASSWORD=password
    volumes:
      - influxdb_data:/var/lib/influxdb
    ports:
      - "8086:8086"
    networks:
      - trading-network

volumes:
  postgres_data:
  redis_data:
  influxdb_data:

networks:
  trading-network:
    driver: bridge
```

## 7. 总结

本详细程序设计文档提供了股票自动交易系统的完整技术实现方案，包括：

### 7.1 核心特性
- **模块化设计**: 清晰的分层架构，便于维护和扩展
- **异步处理**: 高性能的数据处理和并发执行
- **详细日志**: 完整的日志记录体系，支持问题追踪和性能分析
- **实时监控**: 全面的系统监控和告警机制
- **配置管理**: 灵活的配置管理和热更新支持

### 7.2 技术亮点
- **Level2数据处理**: 高效的实时行情数据接收和处理
- **历史评分引擎**: 支持6种评分算法的并行计算
- **策略引擎**: 可扩展的股票池策略框架
- **数据验证**: 完善的数据质量检查机制
- **性能优化**: 批量处理、缓存策略、并行计算

### 7.3 运维支持
- **容器化部署**: Docker和docker-compose支持
- **日志管理**: 结构化日志、日志轮转、日志聚合
- **监控告警**: 系统资源监控、业务指标监控
- **配置管理**: 配置文件管理、版本控制、热更新

该设计文档为开发团队提供了详细的实现指导，确保系统的稳定性、可维护性和可扩展性。

## 8. 安全设计

### 8.1 数据安全
- **数据加密**: 敏感数据加密存储
- **访问控制**: 基于角色的访问控制
- **审计日志**: 记录所有操作日志
- **数据备份**: 定期备份重要数据

### 8.2 系统安全
- **身份认证**: JWT token认证
- **权限管理**: 细粒度权限控制
- **网络安全**: HTTPS通信、防火墙配置
- **代码安全**: 代码审计、依赖扫描

## 9. 监控和运维

### 9.1 系统监控
- **性能监控**: CPU、内存、磁盘、网络使用率
- **业务监控**: 交易成功率、策略执行情况
- **异常监控**: 错误率、响应时间
- **资源监控**: 数据库连接数、缓存命中率

### 9.2 告警机制
- **阈值告警**: 超过预设阈值时告警
- **异常告警**: 系统异常时立即告警
- **业务告警**: 业务指标异常时告警
- **多渠道通知**: 邮件、短信、钉钉等

## 10. 部署架构

### 10.1 容器化部署
```yaml
# docker-compose.yml
version: '3.8'
services:
  trading-system:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/trading
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
      - influxdb
      
  db:
    image: postgres:13
    environment:
      - POSTGRES_DB=trading
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
      
  redis:
    image: redis:6-alpine
    volumes:
      - redis_data:/data
      
  influxdb:
    image: influxdb:2.0
    environment:
      - INFLUXDB_DB=market_data
    volumes:
      - influxdb_data:/var/lib/influxdb2

volumes:
  postgres_data:
  redis_data:
  influxdb_data:
```

### 10.2 高可用部署
- **负载均衡**: Nginx负载均衡
- **服务冗余**: 多实例部署
- **数据库集群**: PostgreSQL主从复制
- **缓存集群**: Redis Cluster
- **监控告警**: Prometheus + Grafana

这个设计文档提供了系统的详细技术架构，包括数据库设计、核心类设计、算法实现和部署方案。接下来我将创建开发计划文档。
