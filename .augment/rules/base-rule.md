---
type: "always_apply"
---

## 概述

本文档定义了 Augment Code AI 助手的基础执行规则，确保开发过程**可追溯、可审计、可回滚**，并**强制兼容华博云项目规范**。所有规则均为**强制性要求**，必须严格遵循。

### 🎯 核心目标
- **提升代码质量**: 通过规范化流程确保代码简洁易懂
- **保证过程可控**: 通过任务拆分和状态跟踪确保执行有序
- **实现完整记录**: 通过对话记录和Git提交实现全程可追溯
- **支持快速回滚**: 通过标准化流程支持问题快速定位和修复
- **⚠️ 强制华博云兼容**: 所有开发活动必须严格遵循华博云项目规范和技术约束

---

## 核心执行原则

> 💡 **重要提示**: 以下原则为强制执行规则，任何违反都需要立即纠正

### 任务管理规范

#### 1. 强制任务拆分机制
- **触发条件**: 每次交互开始时必须进行任务拆分
- **拆分粒度**: 复杂任务必须拆分为 1-3 个明确的子任务
- **时间估算**: 每个子任务预计执行时间约 5-10 分钟
- **执行约束**: 严格按照拆分的任务列表顺序执行，不得跳跃或遗漏

#### 2. 任务状态跟踪
实时更新任务执行状态，确保每个子任务都有明确的完成标记：

| 状态标记 | 含义 | 使用场景 |
|---------|------|----------|
| `[ ]` | 未开始 | 任务创建时的初始状态 |
| `[/]` | 进行中 | 任务正在执行过程中 |
| `[x]` | 已完成 | 任务成功完成并验证 |
| `[-]` | 已取消 | 任务因故取消执行 |
| `[!]` | 执行异常 | 任务执行过程中出现问题 |

#### 3. 执行验证要求
- **完成确认**: 每个子任务完成后必须进行验证
- **状态更新**: 及时更新任务状态标记
- **异常处理**: 遇到执行异常时，记录问题并调整后续任务
- **质量检查**: 确保每个任务的输出符合预期标准

#### 4. 遗漏检查机制
- **检查时机**: 每个任务完成后和整体流程结束前
- **处理方式**: 如发现任务遗漏，立即停止当前执行，返回按计划执行
- **记录要求**: 详细记录遗漏原因和补救措施

### 交互反馈机制

#### MCP Interactive Feedback 规则
> ⚠️ **强制要求**: 以下规则必须严格执行，不得省略

1. **全程反馈要求**: 在任何流程、任务、对话进行时，无论是询问、回复、或完成阶段性任务，皆必须调用 MCP `mcp-feedback-enhanced`
2. **反馈响应机制**: 每当收到用户反馈，若反馈内容非空，必须再次调用 MCP `mcp-feedback-enhanced`，并根据反馈内容调整行为
3. **结束条件**: 仅当用户明确表示「结束」或「不再需要交互」时，才可停止调用 MCP `mcp-feedback-enhanced`
4. **循环执行**: 除非收到结束指令，否则所有步骤都必须重复调用 MCP `mcp-feedback-enhanced`
5. **任务完成前确认**: 完成任务前，必须使用 MCP `mcp-feedback-enhanced` 工具向用户询问反馈

### 记录管理要求

#### 对话记录管理
> 📝 **核心要求**: 必须保存完整的 AI Agent 交互对话记录

##### 记录内容
- 用户输入
- Agent 输出
- 重要工具调用
- 关键信息检索过程

##### 存储规范
- **强制路径**: 项目根目录的 `.chat` 目录
- **文件命名**: `chat-{YYYYMMDD-HHmmss}-{task_id}.jsonl`
- **文件格式**: JSON Lines（.jsonl）或 Markdown（.md）

##### 基本字段结构
```json
{
  "timestamp": "时间戳",
  "role": "角色（user/agent/tool）",
  "content": "内容",
  "task_id": "任务ID",
  "commit_id": "提交ID（如有）",
  "attachments": "附件（可选）"
}
```

##### 版本控制要求
- 所有对话记录文件应纳入 Git 版本管理
- 涉及敏感信息的内容需脱敏处理
- 不允许覆盖已有记录，只允许追加新文件
- 如需修订，使用"修订说明"追加一条记录

---

## Python量化项目规范

> 🐍 **项目核心约束**: 本章节定义了与Python量化脚本项目的强制性兼容要求，所有开发活动必须严格遵循

### 开发规范集成

#### 强制性技术栈要求
- **Python版本**: 必须使用 Python 3.8+ (推荐 3.11+)
- **Level2行情接口**: 必须使用 lev2mdapi 作为Level2行情数据接口
- **数据处理**: 必须使用 pandas、numpy 进行数据处理和数值计算
- **数据库操作**: 必须使用 SQLAlchemy ORM 框架进行数据库操作
- **配置管理**: 必须使用 YAML 或 JSON 格式进行配置管理
- **日志系统**: 必须使用 Python logging 模块进行日志记录
- **包管理**: 必须使用 pip + requirements.txt 或 uv 进行依赖管理

#### lev2mdapi接口使用规范
- **接口库**: 必须使用 lev2mdapi Python库进行Level2行情数据接收
- **回调实现**: 必须继承 CTORATstpLev2MdSpi 类实现回调处理
- **连接方式**: 支持TCP和UDP组播两种连接方式，根据业务需求选择
- **技术文档**: 严格遵循 `开发指南.md`（lev2mdapi C++接口开发指南）中的技术规范
- **核心功能**: 实现连接管理、登录认证、订阅管理等核心功能
- **数据类型**: 处理快照行情、逐笔成交、逐笔委托等不同类型的行情数据

#### 量化分析库要求
- **数据分析**: pandas, numpy, scipy
- **金融计算**: TA-Lib, empyrical, pyfolio
- **数据可视化**: matplotlib, plotly (可选)
- **数据库**: SQLAlchemy, sqlite3, pymysql
- **异步处理**: asyncio, aiofiles
- **数据验证**: pydantic, marshmallow

#### 开发工具集成要求
- **代码格式化**: 必须使用 black + isort 进行代码格式化
- **代码检查**: 必须使用 ruff 或 flake8 + mypy 进行代码质量检查
- **测试框架**: 必须使用 pytest 进行单元测试
- **文档生成**: 使用 Sphinx 或 mkdocs 生成项目文档

### 强制性对接要求

#### 1. 开发流程对接
- **需求分析**: 必须基于量化交易业务场景进行需求分析
- **技术选型**: 必须在Python量化生态技术栈范围内进行选型
- **代码审查**: 必须通过Python代码质量检查工具验证
- **测试验证**: 必须在Python环境中进行功能和性能测试验证

#### 2. 工具链对接
- **开发环境**: 必须使用Python虚拟环境进行依赖隔离
- **构建工具**: 必须使用标准的Python打包和部署方式
- **监控工具**: 必须集成Python logging和性能监控机制

#### 3. 质量标准对接
- **代码规范**: 必须通过PEP 8代码规范检查
- **性能标准**: 必须满足量化交易系统的实时性要求
- **安全标准**: 必须符合金融数据处理的安全规范
- **文档标准**: 必须按照Python项目文档标准编写
- **lev2mdapi规范**: 严格遵循开发指南.md中的接口调用规范和错误处理机制

### lev2mdapi开发规范

#### 技术文档参考
- **主要参考**: `开发指南.md`（lev2mdapi C++接口开发指南）
- **重点章节**: 第3章"接口函数"和第3.4节"附录一：行情接口清单"
- **接口定义**: 包含完整的接口函数说明、参数定义、使用示例
- **最佳实践**: 遵循文档中的技术规范和最佳实践

#### 实现要求
1. **API初始化流程**:
   ```python
   # 严格按照文档中的初始化流程
   api = lev2mdapi.CTORATstpLev2MdApi_CreateTstpLev2MdApi(
       lev2mdapi.TORA_TSTP_MST_TCP,  # 或 TORA_TSTP_MST_MCAST
       cache_mode  # 缓存模式选择
   )
   api.RegisterSpi(spi_instance)
   api.RegisterFront(tcp_address)  # 或 RegisterMulticast
   api.Init()
   ```

2. **回调函数实现**:
   - `OnFrontConnected()`: 前置连接成功处理
   - `OnFrontDisconnected()`: 连接断开处理和重连机制
   - `OnRspUserLogin()`: 用户登录响应处理
   - `OnRtnMarketData()`: 快照行情数据处理
   - `OnRtnTransaction()`: 逐笔成交数据处理
   - `OnRtnOrderDetail()`: 逐笔委托数据处理

3. **连接管理要求**:
   - 实现稳定的连接状态监控
   - 处理TCP和UDP组播两种连接方式
   - 实现自动重连机制，确保连接稳定性
   - 正确处理登录认证流程

4. **数据处理要求**:
   - 确保行情数据处理的实时性（延迟 < 100ms）
   - 实现数据标准化和验证机制
   - 支持多种行情数据类型的并发处理
   - 实现适当的缓存和持久化策略

#### 开发注意事项
- **初始化顺序**: 严格按照 RegisterSpi → RegisterFront → Init 的顺序
- **组播配置**: UDP组播模式下注意网络配置和接口IP设置
- **缓存模式**: 根据数据处理能力选择缓存模式，避免数据丢包
- **异常处理**: 实现完整的异常处理和错误恢复机制
- **资源管理**: 正确释放API资源，避免内存泄漏

---

## 开发规范

### 通用开发礼节

#### 代码质量原则
- **简洁优先**: 优先保证代码简洁易懂，避免过度设计
- **复用导向**: 函数尽量小，尽量可复用，避免重复代码
- **性能考虑**: 注意算法复杂度，应尽可能批量操作数据和数据库
- **模块设计**: 注意模块设计，合理使用设计模式

#### 沟通规范
- **说人话**: 解释代码时使用通俗易懂的语言，避免过度专业术语
- **图表辅助**: 实现和解释时提供原理说明和执行步骤，最好配有 mermaid 图表
- **全面分析**: 改动或解释前，必须查看所有相关代码，不得偷懒
- **最小修改**: 改动前要做最小化修改，尽量不影响其他模块

#### 图表规范
- **语法检查**: 提供的 mermaid 图必须自检语法，确保可被渲染
- **主题适配**: 图表必须在暗黑主题上清晰可见
- **内容完整**: 图表应准确反映代码逻辑和执行流程

#### 测试验证
- **案例设计**: 改动后，假定10条测试用例输入，并给出预期结果
- **边界测试**: 包含正常、异常、边界等多种情况
- **结果验证**: 确保测试结果符合预期

### Git提交规范

#### 提交时机
- **强制要求**: 每次编码工作完成后，必须创建 Git 提交记录
- **提交粒度**: 每个提交应包含一个完整的功能模块或独立可验证的子任务
- **提交频率**: 保持"小步提交、可回滚"原则

#### 提交信息格式
遵循 Conventional Commits 规范：

```text
<type>(<scope>): <description> (#<task_id>)

[optional body]

[optional footer]
```

##### 类型说明
| 类型 | 描述 | 使用场景 |
|------|------|----------|
| `feat` | 新功能 | 添加新的功能特性 |
| `fix` | Bug 修复 | 修复已知问题 |
| `docs` | 文档更新 | 更新文档内容 |
| `style` | 代码格式调整 | 代码风格、格式调整 |
| `refactor` | 代码重构 | 重构现有代码 |
| `test` | 测试相关 | 添加或修改测试 |
| `chore` | 构建过程或辅助工具的变动 | 构建配置、依赖更新等 |
| `perf` | 性能优化 | 提升算法或数据处理性能 |
| `data` | 数据相关 | 数据文件更新、数据结构调整 |

##### 提交示例
```bash
feat(scoring): 新增涨停炸板评分算法 (#TASK-20250115-001)

- 实现涨停炸板识别逻辑
- 添加评分计算公式
- 集成历史数据验证

Closes #123
```

### Bug修复流程

> 🔧 **实验性规则**: 当被要求修复Bug时，请严格遵循以下步骤

#### 标准化修复流程
1. **理解问题 (Understand)**: 仔细阅读 Bug 描述和相关代码，复述对问题的理解
2. **分析原因 (Analyze)**: 提出至少两种可能的根本原因
3. **制定计划 (Plan)**: 描述验证原因的方法，并给出修复方案
4. **请求确认 (Confirm)**: 在动手修改前，向用户确认修复计划
5. **执行修复 (Execute)**: 实施修复方案
6. **审查验证 (Review)**: 检查修改是否存在问题
7. **解释说明 (Explain)**: 解释具体修改内容及原因

#### 修复质量要求
- **根因分析**: 必须找到问题的根本原因，而非仅修复表面现象
- **影响评估**: 评估修复对其他功能的潜在影响
- **测试验证**: 提供测试用例验证修复效果
- **文档更新**: 必要时更新相关文档

#### 量化项目特殊考虑
- **数据一致性**: 确保修复不影响历史数据的一致性
- **算法准确性**: 验证修复后算法计算结果的准确性
- **性能影响**: 评估修复对数据处理性能的影响
- **回测验证**: 必要时进行历史数据回测验证

---

## 质量保证体系

### 执行检查清单

#### 任务管理检查
- [ ] 是否完成任务拆分？
- [ ] 是否按顺序执行？
- [ ] 是否有遗漏任务？
- [ ] 是否更新任务状态？
- [ ] 是否完成验证？

#### Git 提交检查
- [ ] 是否在功能完成后创建提交？
- [ ] 提交信息是否遵循 Conventional Commits 规范？
- [ ] 提交粒度是否合理？
- [ ] 是否包含任务ID？

#### 对话记录检查
- [ ] 是否保存完整的对话记录？
- [ ] 文件命名是否符合规范？
- [ ] 是否存储在正确的目录？
- [ ] 是否纳入版本控制？

#### 代码质量检查
- [ ] 代码是否简洁易懂？
- [ ] 是否遵循项目编码规范？
- [ ] 是否有充分的注释说明？
- [ ] 是否进行了充分测试？

#### Python量化项目兼容性检查
- [ ] 是否符合Python量化技术栈要求？
- [ ] 是否正确使用lev2mdapi接口进行Level2行情数据接收？
- [ ] 是否遵循开发指南.md中的lev2mdapi使用规范？
- [ ] 是否实现了完整的连接管理和重连机制？
- [ ] 是否正确处理各种类型的行情数据回调？
- [ ] 是否通过Python代码规范检查？
- [ ] 是否在Python环境中测试验证？
- [ ] 是否使用Python量化生态的工具和库？
- [ ] 是否满足量化交易系统的性能要求？
- [ ] 是否符合金融数据处理的安全规范？

### 异常处理流程

#### 任务执行异常
1. **发现遗漏** → 立即停止当前执行
2. **重新检查** → 标记遗漏任务
3. **返回执行** → 按原计划继续
4. **记录原因** → 优化后续执行

#### 规则违反处理
1. **Git 提交缺失**: 立即创建补充提交，记录遗漏原因
2. **对话记录缺失**: 补充记录当前会话，标注补充说明
3. **任务状态不一致**: 重新核对任务列表，更正状态标记
4. **质量检查失败**: 重新执行相关任务，确保符合标准

### 调试支持机制

> 📞 **强制调试要求**: 遇到技术问题时必须优先调用Python量化项目调试助手

#### 强制调用场景
以下情况**必须**调用相关调试工具：

1. **数据处理问题排查**
   - pandas数据处理异常或错误
   - numpy数值计算精度问题
   - 数据文件读取或解析失败
   - 内存使用过高或数据处理缓慢

2. **lev2mdapi接口问题**
   - Level2行情连接失败或频繁断线
   - 行情数据接收异常或数据丢失
   - API回调函数执行错误
   - 登录认证失败或订阅失败

3. **算法计算问题**
   - 量化指标计算结果异常
   - 评分算法逻辑错误
   - 策略回测结果不符合预期
   - 数学计算溢出或精度丢失

4. **数据库操作问题**
   - SQLAlchemy连接或查询问题
   - 数据库事务处理异常
   - 数据持久化失败
   - 查询性能问题

5. **环境配置问题**
   - Python虚拟环境配置错误
   - 依赖包版本冲突或缺失
   - 配置文件格式错误
   - 系统资源限制问题

#### 调用标准流程

```markdown
## Python量化项目调试流程
1. **问题识别** → 确认属于量化项目调试场景
2. **数据检查** → 验证输入数据的完整性和正确性
3. **算法验证** → 检查计算逻辑和公式实现
4. **性能分析** → 分析代码执行效率和资源使用
5. **解决方案** → 基于分析结果制定修复方案
6. **验证结果** → 使用测试数据验证修复效果
7. **记录总结** → 记录问题和解决过程
```

#### 量化项目调试工具
- **数据验证工具**: 检查数据质量和完整性
- **算法测试工具**: 验证计算逻辑和结果准确性
- **性能分析工具**: 分析代码执行效率和内存使用
- **回测验证工具**: 使用历史数据验证策略效果

#### 调用示例
```markdown
🔧 **量化项目调试示例**

**问题**: 股票评分计算结果异常
**数据检查**: 验证输入的价格和成交量数据
**算法验证**: 检查评分公式实现和参数配置
**性能分析**: 分析批量计算的执行效率
**解决方案**: 修复数据类型转换和精度问题
**验证结果**: 使用历史数据验证修复后的计算结果
```

### 审计与回滚

#### 审计要求
- 所有开发活动必须有完整记录
- Git 提交历史清晰可追溯
- 对话记录完整保存
- 任务执行状态准确记录
- **数据处理过程可追溯**: 记录数据来源、处理步骤和结果输出
- **算法变更可回溯**: 记录算法参数调整和效果对比

#### 回滚机制
- **代码回滚**: 基于 Git 提交的代码回滚
- **决策回溯**: 基于对话记录的决策回溯
- **进度恢复**: 基于任务状态的进度恢复
- **数据回滚**: 基于数据版本的历史数据恢复
- **配置回滚**: 基于配置文件版本的参数恢复

---

## 实施指南

### 开发者职责
1. **规范遵循**: 严格遵循所有规范要求
2. **及时提交**: 及时创建 Git 提交
3. **记录维护**: 维护完整的对话记录
4. **任务管理**: 按任务拆分执行开发
5. **量化规范**: 确保与Python量化项目开发规范的一致性

### Agent 职责
1. **任务拆分**: 严格执行任务拆分
2. **记录管理**: 自动记录对话过程
3. **强制执行**: 在每次对话结束前，必须主动执行以下操作：
   - 创建 `.chat` 目录（如不存在）
   - 保存完整对话记录到 `.chat/chat-{YYYYMMDD-HHmmss}-{task_id}.jsonl`
   - 执行 `git add .` 和 `git commit` 命令，提交所有更改
4. **可追溯性**: 确保所有操作可追溯
5. **工具集成**: 集成Python量化开发工具
6. **📞 强制调试支持**: 遇到技术问题时必须调用量化项目调试工具：
   - 数据处理问题时优先检查数据质量和算法逻辑
   - 性能问题时使用性能分析工具
   - 环境配置问题时查询Python生态解决方案
   - 记录调试过程和解决方案

### 执行示例

```markdown
## 任务拆分示例
- [/] TASK-20250121-001: 实现股票评分算法
  - [x] 子任务1: 设计评分算法架构 (8m)
  - [x] 子任务2: 实现涨停炸板评分逻辑 (12m)
  - [/] 子任务3: 集成历史数据验证 (10m)

## 量化项目调试示例
- [!] TASK-20250121-002: 修复数据处理性能问题
  - [x] 数据质量检查和算法验证
  - [/] 性能分析和优化方案制定
  - [ ] 批量处理逻辑优化实施
```

### 常见问题处理

#### Q: 如何处理任务拆分过细的情况？
A: 合并相关的小任务，确保每个任务有独立的价值和验收标准。

#### Q: 对话记录文件过大怎么办？
A: 按日期或任务ID分目录存储，单个文件建议不超过10MB。

#### Q: Git提交信息写错了怎么办？
A: 使用 `git commit --amend` 修改最近一次提交，或创建新的修正提交。

#### Q: 什么时候必须调用调试工具？
A: 遇到任何数据处理问题、算法计算异常、性能问题或环境配置问题时，都必须优先调用相关调试工具。

#### Q: 如何确保Python量化项目规范？
A: 严格按照Python量化技术栈要求开发，使用指定的工具和库，通过代码质量检查和测试验证。

#### Q: 数据处理出现精度问题怎么办？
A: 使用Decimal类型进行高精度计算，验证数据类型转换，检查算法实现逻辑。

#### Q: 如何优化大数据量处理性能？
A: 使用pandas的向量化操作，合理使用内存管理，考虑分批处理和并行计算。

#### Q: 如何确保lev2mdapi接口的正确使用？
A: 严格遵循开发指南.md中的技术规范，正确实现回调函数，确保连接稳定性和数据处理实时性。

#### Q: lev2mdapi连接失败怎么办？
A: 检查网络配置、认证信息、API初始化顺序，实现重连机制，参考开发指南.md中的错误处理方案。

#### Q: 如何选择TCP还是UDP组播模式？
A: 根据网络环境和数据处理需求选择，TCP模式稳定性好，UDP组播模式性能高，需要正确配置网络参数。

#### Q: 如何处理lev2mdapi的数据丢包问题？
A: 启用缓存模式，优化回调函数处理逻辑，确保数据处理不阻塞网络线程，实现适当的缓冲机制。

---

**Always respond in 简体中文**

*规则版本: v4.0*  
*最后更新: 2025-01-21*  
*文档状态: 已优化华博云兼容性和调试支持*
